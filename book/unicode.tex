%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                              %%%
%%%     Language Science Press Master File       %%%
%%%         follow the instructions below        %%%
%%%                                              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Everything following a % is ignored
% Some lines start with %. Remove the % to include them

\documentclass[output=inprep,
%  long|short|inprep
%  ,blackandwhite
%  ,smallfont
%  ,draftmode  
		biblatex
		]{LSP/langsci}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                              %%%
%%%          additional packages                 %%%
%%%                                              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% put all additional commands you need in the 
% following files. If you do not know what this might 
% mean, you can safely ignore this section
\usepackage{verbatim}
\input{localmetadata.tex}
\input{localpackages.tex}
\input{localhyphenation.tex}
\input{localcommands.tex}
\bibliography{localbibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                              %%%
%%%             Frontmatter                      %%%
%%%                                              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\maketitle
\frontmatter
% %% uncomment if you have preface and/or acknowledgements
% \include{chapters/preface}
% \include{chapters/acknowledgments}
% \include{chapters/abbreviations}
\tableofcontents
\mainmatter%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                              %%%
%%%             knitr settings                   %%%
%%%                                              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Here are settings for knitr, which will be removed in the .tex file
% spacing of code-chunks is set with the "knitrout" environment in localcommands.tex



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                              %%%
%%%             Chapters                         %%%
%%%                                              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\include{chapters/preface}
\include{chapters/introduction}
\include{chapters/pitfalls}
\include{chapters/ipa_background}
\include{chapters/ipa_meets_unicode}

\include{chapters/orthography_profiles}

\section{Available implementations}
\label{implementations}

To illustrate the practical application of orthography profiles, we have
implemented two different versions of the above specifications, one in Python
and one in R. These two implementations have rather different implementation
histories, and we are not 100\% sure that they will in all situations give the
same results. Also the perfomance with larger datasets differs, and the code is
not always as clean as we would like it to be. In sum, the two implementations
should be considered as `proof of concept' and not as the final word on the
practical application of the specifications above. In our own experience, the
current implementations are sufficiently fast and stable to be useful for
academic practice (e.g. checking data consistency, or analyzing and
transliterating small to medium sized data sets), but they should probably
better not be used for full-scale industry applications.

\subsection*{Installing the R implementation}

The R implementation is available in the package \texttt{qlcData}, which is 
directly available from the central R repository CRAN (Comprehensive R Archive 
Network). The R software environment itself has to be downloaded from its 
website.\footnote{\url{https://www.r-project.org}} After starting the included 
R program, the \texttt{qlcData} package for dealing with orthography profiles can be 
simply installed as follows:

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# download and install the qlcData software}
\hlkwd{install.packages}\hlstd{(}\hlstr{"qlcData"}\hlstd{)}
\hlcom{# load the software, so it can be used}
\hlkwd{library}\hlstd{(qlcData)}
\end{alltt}
\end{kframe}
\end{knitrout}

\noindent The version available through CRAN is the most recent stable version.
To obtain the most recent bug-fixes and experimental additions, please use the
development versions, which is available on
GitHub.\footnote{\url{http://github.com/cysouw/qlcData}} This development
version can be easily installed using the github-install helper software from the
\texttt{devtools} package.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# download and install helper software}
\hlkwd{install.packages}\hlstd{(}\hlstr{"devtools"}\hlstd{)}
\hlcom{# install the qlcData package from GitHub}
\hlstd{devtools}\hlopt{::}\hlkwd{install_github}\hlstd{(}\hlstr{"cysouw/qlcData"}\hlstd{)}
\hlcom{# load the software, so it can be used}
\hlkwd{library}\hlstd{(qlcData)}
\end{alltt}
\end{kframe}
\end{knitrout}

\noindent Inside the \texttt{qlcData} package, there are two functions for
orthography processing, \texttt{write.profile} and \texttt{tokenize}. R includes
help files with illustrative examples, and also a so-called `vignette' with
explanations and examples.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# view help files}
\hlkwd{help}\hlstd{(write.profile)}
\hlkwd{help}\hlstd{(tokenize)}
\hlcom{# view vignette with explanation and examples}
\hlkwd{vignette}\hlstd{(}\hlstr{"orthography_processing"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\noindent Basically, the idea is to use \texttt{write.profile} to produce a
basic orthography profile from some data and then \texttt{tokenize} to apply the
(possibly edited) profile on some data, as exemplified in the next section. This
can of course be performed inside R, but additionally there are two more
interfaces to the R code supplied in the \texttt{qlcData} package: (i) bash
executables and (ii) `shiny' webapps.

The bash executables are little files providing an interface to the R code that
can be used in a shell on a UNIX-alike machine. The location of these
executables is a bit hidden away by the install procedure of R packages. The
location can be found by the following command in R. These executables can be 
used from here, or they can be linked and/or copied to any location as wanted.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# show the path to the bash executables}
\hlkwd{file.path}\hlstd{(}\hlkwd{find.package}\hlstd{(}\hlstr{"qlcData"}\hlstd{),} \hlstr{"exec"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\noindent For example, a good way to use the executables in a terminal is to
make softlinks (using \texttt{ln}) from the executables to a directory in your
PATH, e.g. to \texttt{/usr/local/bin/}. The two executables are named
\texttt{tokenize} and \texttt{writeprofile}

\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\noindent
\ttfamily
\hlstd{}\hlslc{\#\ make\ two\ softlinks\ to\ the\ R\ executables\ in\ bash}\hspace*{\fill}\\
\hlstd{}\hlkwc{ln\ }\hlstd{}\hlopt{{-}}\hlstd{is\ }\hlstr{`Rscript\ {-}e\ 'cat(file.path(find.package("qlcData"),}\hspace*{\fill}\\
\hlstr{\ "exec",\ "tokenize"))'`}\hlstd{\ }\hlopt{/}\hlstd{usr}\hlopt{/}\hlstd{}\hlkwb{local}\hlstd{}\hlopt{/}\hlstd{bin}\hspace*{\fill}\\
\hlkwc{ln\ }\hlstd{}\hlopt{{-}}\hlstd{is\ }\hlstr{`Rscript\ {-}e\ 'cat(file.path(find.package("qlcData"),}\hspace*{\fill}\\
\hlstr{\ "exec",\ "writeprofile"))'`}\hlstd{\ }\hlopt{/}\hlstd{usr}\hlopt{/}\hlstd{}\hlkwb{local}\hlstd{}\hlopt{/}\hlstd{bin}\hspace*{\fill}
\mbox{}
\normalfont
\end{kframe}
\end{knitrout}

\noindent After this addition it should be possible to access the \texttt{tokenize}
function from the shell. Try \texttt{tokenize --help} to test the functionality.

\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\noindent
\ttfamily
\hlstd{tokenize\ }\hlopt{{-}{-}}\hlstd{}\hlkwb{help}\hlstd{}\hspace*{\fill}
\mbox{}
\normalfont

\begin{verbatim}
## USAGE: 
##   tokenize [-hlrd] [-s SEP -p REPL] [-t TRANS -m MISSING] [<STRINGS> <PROFILE>]
## 
## DESCRIPTION:
##   Using the function tokenize() from the R-package qlcData for tokenization and
##   transliteration of character strings based on an orthography profile. Details
##   http://www.rdocumentation.org/packages/qlcData/functions/tokenize.html
## 
##   STRINGS can be piped through. When no PROFILE is specified, default Unicode
##   tokenization is performed. Note that the R-code allows for even more options,
##   not all options are made available here for ease of use.
##   Errors are likewise (not yet) returned
## 
## OPTIONS:
##   -h, --help      Showing this help text
##   -l, --linear    Use linear method instead of default global method
##   -r, --regex     Use regex matching, including contexts in matching graphemes
##   -d, --NFD       Use NFD normalization instead of default NFC
##   -s SEP          Separator to be inserted after tokenization
##                     defaults to space [default: SPACE]
##   -p REPL         Replacement symbol in case separator occurs in the STRINGS
##                     defaults to nothing [default: NULL]
##   -t TRANS        Column in profile to use for transliteration [default: NULL]
##   -m MISSING      Character to be inserted for characters not in the PROFILE
##                     defaults to DOUBLE QUESTION MARK at U+2047 [default: ⁇]
## 
## EXAMPLES:
##   Try the difference between the following:
## 
##     tokenize áüî
##     tokenize --NFD -s '__' áüî
##   
##   Piping strings should work:
##   
##     ls | tokenize
\end{verbatim}
\end{kframe}
\end{knitrout}

To make the functionality even more accessible, we have prepared webapps with 
the \texttt{shiny} framework for the R functions. These webapps are available 
online at \url{TODO}. The webapps are also included inside the \texttt{qlcData} 
package and can be started with the following helper function:

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{launch_shiny}\hlstd{(}\hlstr{"tokenize"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection*{Installung the Python implementation}

TO DO

\section{Abstract examples}

\subsection*{Error reporting}

In the following example, it looks as if we have two identical strings,
\texttt{AABB}. However, this is just an surface-impression delivered by the
current font, which renders Latin and Cyrillic capitals identically. We can
identify this problem when we produce an orthography profile from the strings.
Using here the R implementation of orthography profiles, we first assign the two
strings to a variable \texttt{test}, and then produce an orthography profile
with the function \texttt{write.profile}. As it turns out, some of the letters 
are Cyrillic.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{test} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"AABB"}\hlstd{,} \hlstr{"AАBВ"}\hlstd{)}
\hlkwd{write.profile}\hlstd{(test)}
\end{alltt}
\begin{verbatim}
##   Grapheme Frequency Codepoint                UnicodeName
## 1        A         3    U+0041     LATIN CAPITAL LETTER A
## 2        B         3    U+0042     LATIN CAPITAL LETTER B
## 3        А         1    U+0410  CYRILLIC CAPITAL LETTER A
## 4        В         1    U+0412 CYRILLIC CAPITAL LETTER VE
\end{verbatim}
\end{kframe}
\end{knitrout}

\noindent The working of error-message reporting can also nicely be illustrated with this
example. Suppose we made an orthography profile with just the Latin <A> and <B> 
as possible graphemes, then this profile would not be sufficient to tokenize the 
strings. There are graphemes in the data that are not in the profile, so the 
tokenization produces an error, which can be used to fix the encoding. In the 
example below, we can see that the Cyrillic encoding is found in the second 
string of the \texttt{test} input.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{test} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"AABB"}\hlstd{,} \hlstr{"AАBВ"}\hlstd{)}
\hlkwd{tokenize}\hlstd{(test,} \hlkwc{profile} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"A"}\hlstd{,} \hlstr{"B"}\hlstd{))}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning in tokenize(test, profile = c("{}A"{}, "{}B"{})): \\\#\# There were unknown characters found in the input data.\\\#\# Check output\$errors for a table with all problematic strings.}}\begin{verbatim}
## $strings
##   originals tokenized
## 1      AABB   A A B B
## 2      AАBВ   A ⁇ B ⁇
## 
## $profile
##   matched_rules Grapheme
## 1             3        B
## 2             3        A
## 
## $errors
##   originals  errors
## 2      AАBВ A ⁇ B ⁇
## 
## $missing
##   Grapheme Frequency Codepoint                UnicodeName
## 1        А         1    U+0410  CYRILLIC CAPITAL LETTER A
## 2        В         1    U+0412 CYRILLIC CAPITAL LETTER VE
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsection*{Different ways to write a profile}

The preparation of an orthography profile from some data might sound like a 
trivial problem, but actually there are various different ways in which strings 
can be separated into graphemes by \texttt{write.profile}. Consider the 
following example string. The default settings of \texttt{write.profile} 
separates the string into Unicode graphemes according to grapheme clusters 
(`user-perceived characters', see Section~\ref{the-unicode-approach}).

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{example} \hlkwb{<-} \hlstr{"ÙÚÛÙÚÛ"}
\hlstd{profile_1} \hlkwb{<-} \hlkwd{write.profile}\hlstd{(example)}
\end{alltt}
\end{kframe}
\end{knitrout}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jun 22 12:03:05 2016
\begin{table}[H]
\centering
\begingroup\scriptsize
\begin{tabular}{llll}
  \toprule
Gr. & Freq. & Codepoint & Unicode Name \\ 
  \midrule
Ú & 1 & U+00DA & LATIN CAPITAL LETTER U WITH ACUTE \\ 
  Ú & 1 & U+0055, U+0301 & LATIN CAPITAL LETTER U, COMBINING ACUTE ACCENT \\ 
  Ù & 1 & U+00D9 & LATIN CAPITAL LETTER U WITH GRAVE \\ 
  Ù & 1 & U+0055, U+0300 & LATIN CAPITAL LETTER U, COMBINING GRAVE ACCENT \\ 
  Û & 1 & U+00DB & LATIN CAPITAL LETTER U WITH CIRCUMFLEX \\ 
  Û & 1 & U+0055, U+0302 & LATIN CAPITAL LETTER U, COMBINING CIRCUMFLEX ACCENT \\ 
   \bottomrule
\end{tabular}
\endgroup
\caption{Profile 1 (default settings, splitting grapheme clusters)} 
\label{tab:profile1}
\end{table}


\noindent Some of these graphemes are single codepoints, others are combinations
of two codepoints. By specifying the separator as empty, it is possible to split
the string into codepoints.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{profile_2} \hlkwb{<-} \hlkwd{write.profile}\hlstd{(example,} \hlkwc{sep} \hlstd{=} \hlstr{""}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jun 22 12:03:05 2016
\begin{table}[H]
\centering
\begingroup\scriptsize
\begin{tabular}{llll}
  \toprule
Grapheme & Frequency & Codepoint & Unicode Name \\ 
  \midrule
́ & 1 & U+0301 & COMBINING ACUTE ACCENT \\ 
  ̀ & 1 & U+0300 & COMBINING GRAVE ACCENT \\ 
  ̂ & 1 & U+0302 & COMBINING CIRCUMFLEX ACCENT \\ 
  U & 3 & U+0055 & LATIN CAPITAL LETTER U \\ 
  Ú & 1 & U+00DA & LATIN CAPITAL LETTER U WITH ACUTE \\ 
  Ù & 1 & U+00D9 & LATIN CAPITAL LETTER U WITH GRAVE \\ 
  Û & 1 & U+00DB & LATIN CAPITAL LETTER U WITH CIRCUMFLEX \\ 
   \bottomrule
\end{tabular}
\endgroup
\caption{Profile 2 (splitting by codepoints)} 
\label{tab:profile2}
\end{table}


\noindent Some characters look identical, although they are encoded differently. 
Unicode offers different ways of normalization, which can be invoked here as 
well (see Section~\ref{pitfall-canonical-equivalence}).

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# after NFC normalization unicode codepoints have changed}
\hlstd{profile_3} \hlkwb{<-} \hlkwd{write.profile}\hlstd{(example,} \hlkwc{normalize} \hlstd{=} \hlstr{"NFC"}\hlstd{,} \hlkwc{sep} \hlstd{=} \hlstr{""}\hlstd{)}
\hlcom{# NFD normalization gives yet another structure of the codepoints}
\hlstd{profile_4} \hlkwb{<-} \hlkwd{write.profile}\hlstd{(example,} \hlkwc{normalize} \hlstd{=} \hlstr{"NFD"}\hlstd{,} \hlkwc{sep} \hlstd{=} \hlstr{""}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jun 22 12:03:05 2016
\begin{table}[H]
\centering
\begingroup\scriptsize
\begin{tabular}{llll}
  \toprule
Grapheme & Frequency & Codepoint & Unicode Name \\ 
  \midrule
Ú & 2 & U+00DA & LATIN CAPITAL LETTER U WITH ACUTE \\ 
  Ù & 2 & U+00D9 & LATIN CAPITAL LETTER U WITH GRAVE \\ 
  Û & 2 & U+00DB & LATIN CAPITAL LETTER U WITH CIRCUMFLEX \\ 
   \bottomrule
\end{tabular}
\endgroup
\caption{Profile 3 (splitting by NFC codepoints)} 
\label{tab:profile3}
\end{table}


% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jun 22 12:03:05 2016
\begin{table}[H]
\centering
\begingroup\scriptsize
\begin{tabular}{llll}
  \toprule
Grapheme & Frequency & Codepoint & Unicode Name \\ 
  \midrule
́ & 2 & U+0301 & COMBINING ACUTE ACCENT \\ 
  ̀ & 2 & U+0300 & COMBINING GRAVE ACCENT \\ 
  ̂ & 2 & U+0302 & COMBINING CIRCUMFLEX ACCENT \\ 
  U & 6 & U+0055 & LATIN CAPITAL LETTER U \\ 
   \bottomrule
\end{tabular}
\endgroup
\caption{Profile 4 (splitting by NFD codepoints)} 
\label{tab:profile4}
\end{table}


\noindent It is important to realize that for Unicode grapheme definitions, NFC 
and NFD normalization are equivalent. This can be shown by normalizing the 
example in either NFC or NFD, but using default separation in 
\texttt{write.profile}. To be precise, default separation means setting \texttt{sep = NULL} 
but that has not be added explicitly.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# note that NFC and NFD normalization are identical for unicode grapheme}
\hlcom{# definitions}
\hlstd{profile_5} \hlkwb{<-} \hlkwd{write.profile}\hlstd{(example,} \hlkwc{normalize} \hlstd{=} \hlstr{"NFD"}\hlstd{)}
\hlstd{profile_6} \hlkwb{<-} \hlkwd{write.profile}\hlstd{(example,} \hlkwc{normalize} \hlstd{=} \hlstr{"NFC"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jun 22 12:03:05 2016
\begin{table}[H]
\centering
\begingroup\scriptsize
\begin{tabular}{llll}
  \toprule
Gr. & Freq. & Codepoint & Unicode Name \\ 
  \midrule
Ú & 2 & U+0055, U+0301 & LATIN CAPITAL LETTER U, COMBINING ACUTE ACCENT \\ 
  Ù & 2 & U+0055, U+0300 & LATIN CAPITAL LETTER U, COMBINING GRAVE ACCENT \\ 
  Û & 2 & U+0055, U+0302 & LATIN CAPITAL LETTER U, COMBINING CIRCUMFLEX ACCENT \\ 
   \bottomrule
\end{tabular}
\endgroup
\caption{Profile 5 (splitting by graphemes after NFD)} 
\label{tab:profile5}
\end{table}


% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jun 22 12:03:05 2016
\begin{table}[H]
\centering
\begingroup\scriptsize
\begin{tabular}{llll}
  \toprule
Gr. & Freq. & Codepoint & Unicode Name \\ 
  \midrule
Ú & 2 & U+00DA & LATIN CAPITAL LETTER U WITH ACUTE \\ 
  Ù & 2 & U+00D9 & LATIN CAPITAL LETTER U WITH GRAVE \\ 
  Û & 2 & U+00DB & LATIN CAPITAL LETTER U WITH CIRCUMFLEX \\ 
   \bottomrule
\end{tabular}
\endgroup
\caption{Profile 6 (splitting by graphemes after NFC)} 
\label{tab:profile6}
\end{table}


\noindent Note that these different profiles can also be produced using the bash 
executable \texttt{writeprofile} (see \ref{implementations} for notes on how to 
install the bash executable). Exactly this example is also included in the help 
file of the executable.

\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\noindent
\ttfamily
\hlstd{writeprofile\ }\hlopt{{-}{-}}\hlstd{}\hlkwb{help}\hlstd{}\hspace*{\fill}
\mbox{}
\normalfont

\begin{verbatim}
## USAGE: 
##   writeprofile [-hie] [-s SEP] [-n NORMALIZE] [<STRINGS>]
## 
## DESCRIPTION:
##   Using the function write.profile() from the R-package qlcData to prepare 
##   a skeleton for an orthography profile to be used with tokenize. Details:
##   http://www.rdocumentation.org/packages/qlcData/functions/readwrite_orthography
## 
##   STRINGS can be piped through. The results is a tab-delimited file for manual
##   editing. Note that the R-code allows for even more options, not all options 
##   are made available here for ease of use.
## 
## OPTIONS:
##   -h, --help      Showing this help text
##   -i, --info      Add columns with Unicode information to profile
##   -e, --editing   Add empty columns for easy editing of profile
##   -s SEP          Separator used to separate the strings
##                     Often useful is option UNI to split by unicode codepoints
##                     defaults to unicode character definition [default: NULL]
##   -n NORMALIZE    Normalization used to make profile. Possible options: NFD, NFC
##                     defaults to no normalization [default: NULL]
##                     
## EXAMPLES:
##   Note the differences between the following variants:
## 
##     example='ÙÚÛÙÚÛ'
##     echo -e $example
##     echo -e $example | writeprofile -i
##     echo -e $example | writeprofile -i -s UNI
##     echo -e $example | writeprofile -i -s UNI -n NFC
##     echo -e $example | writeprofile -i -s UNI -n NFD
\end{verbatim}
\end{kframe}
\end{knitrout}


\include{chapters/use_cases}

\chapter{Testing code inclusion}


Trying to include code through knitr. 
Different languages can be easily 
included!

There is a bug for non-R engines: the fontsize settings and line spaceing are not correct. I have 
filed an issue, hopefully this will be fixed soon. 

For syntax colouring, install the package `highlight' and for nice tables 
install the package `xtable'.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\noindent
\ttfamily
\hlstd{}\hlkwb{echo\ }\hlstd{}\hlstr{'this\ is\ a\ simple\ bash\ example'}\hlstd{}\hspace*{\fill}\\
\hlkwc{ls\ }\hlstd{\textbar \ }\hlkwc{wc}\hlstd{}\hspace*{\fill}
\mbox{}
\normalfont

\begin{verbatim}
## this is a simple bash example
##       11      11     184
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{verbatim}
## note that bash chunks are executed as one, with all output at the end.
## You will have to make different chunks to get output separated.
## And add manual linebreaks!
\end{verbatim}
\end{kframe}
\end{knitrout}

Spacing of lines is fine. I think without background looks better

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# adding comments inside code? Probably not a good idea}
\hlstd{(example} \hlkwb{<-} \hlstr{"this is a simple R example"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] "this is a simple R example"
\end{verbatim}
\begin{alltt}

\hlstd{test} \hlkwb{<-} \hlnum{3} \hlopt{+} \hlnum{4}
\hlstd{test}
\end{alltt}
\begin{verbatim}
## [1] 7
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(qlcData)}
\hlstd{profile} \hlkwb{<-} \hlkwd{write.profile}\hlstd{(}\hlstr{"AΑА"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

% latex table generated in R 3.3.0 by xtable 1.8-2 package
% Wed Jun 22 10:58:23 2016
\begin{table}[H]
\centering
\begingroup\small
\begin{tabular}{llll}
  \toprule
Grapheme & Frequency & Codepoint & UnicodeName \\ 
  \midrule
A & 1 & U+0041 & LATIN CAPITAL LETTER A \\ 
  Α & 1 & U+0391 & GREEK CAPITAL LETTER ALPHA \\ 
  А & 1 & U+0410 & CYRILLIC CAPITAL LETTER A \\ 
   \bottomrule
\end{tabular}
\endgroup
\caption{test} 
\label{bla}
\end{table}




You can refer to variables by using \textbackslash Sexpr{}. 
For example, the length of the example string is 26.
Crossreferencing also works, see Table~\ref{bla}.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\noindent
\ttfamily
\hlstd{}\hlkwa{print}\hlstd{}\hlopt{(}\hlstd{}\hlstr{'bla'}\hlstd{\ }\hlopt{+\ }\hlstd{}\hlstr{'bla'}\hlstd{}\hlopt{)}\hspace*{\fill}\\
\hlstd{}\hlkwa{print}\hlstd{}\hlopt{(}\hlstd{}\hlnum{3}\hlstd{}\hlopt{+}\hlstd{}\hlnum{4}\hlstd{}\hlopt{)}\hlstd{}\hspace*{\fill}
\mbox{}
\normalfont

\begin{verbatim}
## blabla
## 7
\end{verbatim}
\end{kframe}
\end{knitrout}

You have to add the option ``engine.path='python3'' to get Python 3.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{1, 1, 1}\color{fgcolor}\begin{kframe}
\noindent
\ttfamily
\hlstd{}\hlkwa{print}\hlstd{}\hlopt{(}\hlstd{}\hlstr{'python3\ needs\ an\ extra\ tag'}\hlstd{}\hlopt{)}\hspace*{\fill}\\
\hlstd{uni\ }\hlopt{=\ }\hlstd{}\hlstr{'aɽɮz'}\hlstd{}\hspace*{\fill}\\
\hlkwa{print}\hlstd{}\hlopt{(}\hlstd{uni}\hlopt{)}\hlstd{}\hspace*{\fill}
\mbox{}
\normalfont

\begin{verbatim}
## python3 needs an extra tag
## aɽɮz
\end{verbatim}
\end{kframe}
\end{knitrout}

Testing: does referencing to variables also work in Python? It does give an error, so no... !


% TODOS:

% Lots of characters within <> were lost in translation...
% some things to note in the translation to LaTeX:
% tildes in URLs broken -- turned into \textasciitilde{}
% <a> etc. seem to sometimes be lost
% section in some cases should be "chapter"


% other stuff to fix / proof read
% references
% sections, e.g. Section 4, Pitfall 4)
% URLs
% `', ``''
% reinsertion of a lot of the glyphs, etc.
% fix ligatures
% all glyphs need to be checked
% all <>s need to be checked and/or readded

\begin{comment}
===
Double quotation marks are generally used for distancing, in particular in the following situations:

1. when a passage from another work is cited in the text (e.g. According to Takahashi (2009: 33), “quotatives were never used in subordinate clauses in Old Japanese”); but block quotations do not have quotation marks;
2. when a technical term is mentioned that the author does not want to adopt, but wants to mention, e.g. This is sometimes called “pseudo-conservatism”, but I will not use this term here, as it could lead to confusion.

Single quotation marks are used exclusively for linguistic meanings, as in the following: Latin habere ‘have’ is not cognate with Old English hafian ‘have’.

===
so, we should normally use double quotation in most of our cases :-). In general though, I would like us to try and remove double quotations as much as possible. Mostly is thus signals uncertainty on our part :-).

\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                              %%%
%%%             Backmatter                       %%%
%%%                                              %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% There is normally no need to change the backmatter section
\input{backmatter.tex}
\end{document}

% you can create your book by running
% xelatex lsp-skeleton.tex
%
% you can also try a simple 
% make
% on the commandline
