\chapter{IPA meets Unicode}
\label{ipa-meets-unicode}

The International Phonetic Alphabet (IPA) is a common standard in linguistics to
transcribe sounds of spoken language into discrete segments using a Latin-based 
alphabet. Although IPA is reasonably easily adhered to with pen and paper, it is not trivial to encode
IPA characters electronically. Similar to the previous chapter, in this chapter
we discuss various pitfalls with the encoding of IPA in the Unicode Standard.\@ We will
specifically refer to the 2005 version of the IPA \citep{IPA2005} and the 7.0 
version of Unicode \citep{Unicode2014}.

The details of the encoding are unimportant as long as the
transcription is only directed towards phonetically trained eyes. For a linguist
reading an IPA transcription, many of the details that will be discussed in this
chapter might seem like hair-splitting trivialities. However, if IPA
transcriptions are intended to be used across resources (e.g.~searching similar
phenomena across different languages) then it becomes crucial that there are strict
encoding guidelines. Our main goal in this chapter is to present the encoding
issues and propose recommendations for a ``strict'' IPA encoding.

There are several pitfalls to be aware of when using the Unicode Standard to
encode IPA.\@ As we have said before, from a linguistic perspective it might
sometimes look like the Unicode Consortium is making incomprehensible decisions,
but it is important to realize that the consortium has tried and is continuing
to try to be as consistent as possible across a wide range of use cases, and it
does place linguistic traditions above other orthographic possibilities. Furthermore, 
when we look at the history of how the IPA meet Unicode, we see that many of the 
decisions for IPA symbols in the Unicode Standard come directly from the 
International Phonetic Association itself. Therefore as users, many pitfalls that we 
encounter have their grounding in the historical principles of the IPA, as 
well as the technological considerations involved in creating a single 
multilingual computing encoding.

In general, we strongly suggest to linguists to not complain about any decisions in
the Unicode Standard, but to try and understand the rationale of the International Phonetic Association 
and the Unicode Consortium (which in our experience is almost always well-conceived) and devise
ways to work with any unexpected behavior. Many of the current problems derive
from the fact that the IPA is clearly historically based on the Latin script,
but different enough from most other Latin-based writing systems to warrant
special attention. This ambivalent status of the IPA glyphs (partly Latin,
partly special) is unfortunately also attested in the treatment of IPA in the
Unicode Standard. In retrospect, it might have been better to consider the IPA
(and other transcription systems) to be a special kind of script within
the Unicode Standard, and treat the obvious similarity to Latin glyphs as a
historical relic. All IPA glyphs would then have their own code points, instead
of the current situation in which some IPA glyphs have special code points,
while others are treated as being identical to the regular Latin characters.
Yet, the current situation, however unfortunate, is unlikely to change, so as
linguists we must learn to deal with the specific pitfalls of IPA within
the Unicode Standard. 

In the following sections, we will describe these pitfalls 
in detail. But first we present a brief history of IPA, its principles, 
its computational representation and the need for and challenge in creating 
a single multilingual computer encoding, and then how IPA meet Unicode.

% ==========================
\section{The International Phonetic Alphabet (IPA)}
\label{the-international-phonetic-alphabet}
% ==========================

\subsection{Brief history}

Established in 1886, the International Phonetic Association (henceforth Association) 
has long maintained a standard alphabet, the International Phonetic Alphabet (IPA),
\footnote{Also referred to as API, for \textit{Association Phonétique Internationale}.} 
which is a common standard in linguistics to transcribe sounds of spoken languages. 
It was first published in 1888 as an international system of phonetic transcription 
for oral languages and for pedagogical purposes. The draft of 1887 contained phonetic 
values for English, French and German. Diacritics for length and nasalization were 
already present in this draft and the same symbols are still used today. 

Although the original IPA alphabet was a list of symbols with pronunciation examples 
from words in different languages, in 1900 the symbols were organized into chart form and 
given phonetic feature labels for consonants (e.g.\ for manner of articulation: `plosives', 
`nasales', `fricatives'; for place of articulation: `bronchials', `laryngeales', `labiales') 
and for vowels (`fermeées', `mi-fermeées', `mi-overtes', `overtes'). Over the last century 
or so, the structure of the chart has changed with increases in phonetic knowledge, and 
thus like notational systems in other scientific disciplines, the IPA reflects facts and 
theories (of phonetic knowledge) that have developed over time. It is natural then that 
the IPA is modified occasionally to accommodate scientific innovations and discoveries. 
(In fact, this is part of the Association's mandate.) These changes are captured in 
the revisions to the IPA.\footnote{For a detailed history see: 
\url{https://en.wikipedia.org/wiki/History\_of\_the\_International\_Phonetic_Alphabet}}

Over the years there has been many revisions, most minor. For example, 
articulation labels -- what we now call features even though the IPA avoids this term -- 
have changed (e.g.\ `lips', `throat', `rolled'). Phonetic symbol values have changed 
(e.g.\ voiceless is no longer marked by <h>). Symbols have been dropped (e.g.\ the 
caret diacritic denoting `long and narrow' is longer used). And many symbols have 
been added to reflect contrastive sounds found in the world's very diverse 
phonological systems.

Although IPA began its life as a pedagogical tool, from its earliest days the 
Association aimed to provide ``a separate sign for each distinctive sound; 
that is, for each sound which, being used instead of another, in the same 
language, can change the meaning of a word'' \citep[27]{IPA1999}. Distinctive 
sounds became later known as \textsc{phonemes} and the IPA has developed historically 
into a notational devise with a strictly segmented phonemic view. A phoneme is an 
abstract theoretical notion derived from an acoustic signal as produced by speakers 
in the real world. Therefore the IPA contains a number of theoretical assumptions 
about speech and how to analyze speech in written form. 

Phonetic analysis is based on two premises: that it is possible to describe 
the acoustic speech signal (i.e.\ sound waves) in terms of sequentially ordered 
discrete segments, and, that each segment can be characterized by an articulatory 
target.\footnote{A purely phonetic description is only derivable from instrumental 
data in high quality sound recordings. Once spoken language data are segmented, 
phonological consideration inextricably play a roll in transcription. In other 
words, phonetic observations beyond quantitative acoustic analysis are made in 
terms of some phonological framework.} Today, the IPA chart reflects a linguistic 
basis grounded in principles of phonological contrast. This fact is stated 
explicitly in several places, including in the \textit{Report on the 1989 Kiel 
convention} published in the \textit{Journal of the International Phonetic 
Association} \citep[67-68]{International1989report}:

\begin{quote}
The IPA is intended to be a set of symbols for representing all the possible 
sounds of the world's languages. The representation of these sounds uses a set 
of phonetic categories which describe how each sound is made. These categories 
define a number of natural classes of sounds that operate in phonological rules 
and historical sound changes. The symbols of the IPA are shorthand ways of 
indicating certain intersections of these categories.
\end{quote}

\noindent and in the \textit{Handbook of the International Phonetic Association} \citep[18]{IPA1993}: 

\begin{quote}
% The general value of the symbols in the chart is listed below. In each case 
... a symbol can be regarded as a shorthand equivalent to a phonetic description, 
and a way of representing the contrasting sounds that occur in a language. Thus 
[m] is equivalent to `voiced bilabial nasal', and is also a way of representing 
one of the contrasting nasal sounds that occur in English and other languages. 
[...] When a symbol is said to be suitable for the representation of sounds in 
two languages, it does not necessarily mean that the sounds in the two languages 
are identical.
\end{quote}

\noindent Although the IPA provides symbols to unambiguously represent phonemes, 
it also aims to represent phonetic details. Since phonetic detail could potentially 
include things like `deep voice', the IPA restricts phonetic detail to linguistically 
relevant aspects of speech. These principles and conventions for using the IPA are 
outlined in the Association's Handbook.


\subsection{Principles}

IPA transcription has essentially two parts. The first is a text containing IPA 
symbols and the second is a set of conventions (rules) for interpreting those 
symbols (and their combinations). The IPA is designed to meet practical linguistic 
needs and is used to transcribe the phonetic or phonological structure of languages. 
It is also used increasingly as a foreign language learning tool, as a standard 
pronunciation guide and as a tool for creating practical orthographies of 
previously unwritten languages. 

The current construction and use of the IPA are guided by principles outlined 
in the \textit{Handbook of the International Phonetic Association: A guide 
to the use of the International Phonetic Alphabet} \citep[159]{IPA1999}, henceforth 
HB. The use of the symbols to represent a language's phonological system is guided 
by the principle of contrast; where two words are distinguishable by phonetic contrast, 
those contrasts should be transcribed with different symbols (graphemes not diacritics). 
Allophonic distinction falls under the rubric of diacritically-distinguished symbols, 
e.g. [stop̚] vs [spʰot]. In sum:

\begin{itemize}
	\item different symbols (without diacritics) should be used whenever a language employs two contrastive sounds
	\item when two sounds in a language are not known to be contrastive, the same symbol should be used to represent these sounds; however, diacritics may be used to distinguish such sounds when necessary
	\item diacritics cannot be dispensed with entirely, so the Association recommends to limit their use to:
	\begin{itemize}
		\item denoting length, stress and pitch
		\item representing minute shades of sounds
		\item obviating the design of a (large) number of new symbols when a single diacritic suffices (e.g. nasalized vowels, aspirated stops)
	\end{itemize}
\end{itemize}	

\noindent Thus, an IPA transcription \textit{always} consists of ``a set of 
symbols and a set of conventions for their interpretation''. 

In systematic transcription (as opposed to impressionistic), there is a division 
between phonemic and allophonic transcription. The terms phoneme and allophone 
contain theoretical baggage, but the basic goal of a phonemic transcription is to 
distinguish all words in a language with the minimal number of transcription 
symbols \citep[19]{Abercrombie1964}. Allophonic transcription uses a broader 
set of distinct symbols to describe systematic allophonic differences in sounds 
in words. These two systematic transcriptions are related to each other by a 
set of conventions in the IPA tradition, so that they can be converted between 
one and another.

An IPA transcription is connected to a speech event by a set of conventions. 
A phonetic (or impressionistic) transcription may use the conventions implicit 
in the IPA chart, i.e. the transcriber can indicate that the phonetic value of 
<ŋ͡m> is a simultaneous labial and velar closure which is voiced and contains 
nasal airflow. 

A phonemic transcription includes the conventions of a particular language's 
phonological rules. These rules determine the realization of that language's 
phonemes. However, there can be different systems of phonemic transcription 
for the same variety of a language. The differences may result from the fact 
that more than one phonetic symbol may be appropriate for a phoneme (see Section 
\ref{}). Or the differences may be due to different phonemic analyses, e.g.\ 
Standard German's vowel system is arguably contrastive in length or tenseness.

An important principle of the IPA is that different representations resulting 
from different symbols and different analyses are in line with the IPA's aims. 
In other words, the IPA does not provide phonological analyses for specific 
languages and the IPA does not define a single ``correct'' transcription system. 
Rather, the IPA aims to provide a resource that allows users to express any 
analysis so that it is widely understood. Thus the IPA suits many linguists' 
needs because:

\begin{itemize}
	\item it is intended to be a set of symbols for representing all possible sounds in the world's (spoken) languages
	\item its chart has a linguistic basis (specifically a phonological bias) rather than a general phonetic notation scheme
	\item its symbols can be used to represent distinctive feature combinations\footnote{Although the chart uses traditional manner and place of articulation labels, the symbols can nevertheless represent any defined bundle of features, binary or otherwise, to define phonetic dimensions.}
	\item its chart provides a summary of linguists' agreed-upon phonetic knowledge (a common denominator of phonological ``facts'')
\end{itemize}

Several styles of transcription with IPA are possible and the HB illustrates 
these and notes that they are all valid (see the 29 languages and their transcriptions 
in the original and initial \textit{Illustrations of the IPA} \citep[41--154]{IPA2007}). 
Therefore, there are different but equivalent transcriptions, or as \cite[64]{Ladefoged1990a} 
captures it, ``Perhaps now that the Association has been explicit in its eclectic 
approach, outsiders to the Association will no longer speak of \textit{the} IPA 
transcription of a given phenomenon, as if there were only one approved style.''.

Clearly not all phoneticians agree (or will likely ever agree of course) on all 
aspects of the IPA or on transcription practices. As noted above, there have 
been several revisions in the IPA's long history, but the current version (2005) 
is strikingly similar to the 1926 version. In 1989 an IPA revision convention 
was held in Kiel, Germany. As per other revisions, there was expansion and revisions 
to phonetic symbols in the IPA chart. Notably the marking of tone was extended 
with the addition of a second system for marking linguistic tones (Chao tones). 
Importantly, however, this was the first revision to address issues of 
computational representations for the IPA -- the principles above of which 
have had several ramifications that make the interoperability of electronic 
linguistic data extremely difficult.


\subsection{Computational representation}

Prior to the Kiel Convention for the modern revision of the IPA in 1989, 
\cite{Wells1987} collected and published practical approaches to coded 
representations of the IPA, which dealt mainly with the assignment of 
characters on the keyboard. The process of assigning standardized ``computer 
codes'' to phonetic symbols was assigned to the Workgroup on Computer 
Coding (henceforth working group) at the Kiel Convention. This working 
group was tasked with \citep{Esling1990,EslingGaylord1993}: 

\begin{itemize}
	\item determining how to represent the IPA numerically
	\item developing a set of numbers to refer to the IPA symbols unambiguously
	\item providing each symbol a unique name (intended to provide a mnemonic description of that character's shape)
\end{itemize}

\noindent The identification of IPA symbols with unique identifiers was 
a first step in formalizing the IPA computationally because it would give 
each symbol an unambiguous numerical identifier called an \textsc{IPA Number}. 
The numbering system was to be comprehensive enough to support future revisions 
of the IPA, including symbol specifications and diacritic placement. The 
application of diacritics was also to be made explicit. 

Although the Association had never officially approved a set of names 
for the IPA symbols, each IPA symbol received a unique \textsc{IPA Name}. 
Many symbols already had an informal name (or two) used by linguists, but 
consensus on symbol names was growing due to the recent publication of the 
\textit{Phonetic Symbol Guide} \citep{PullumLadusaw1986}. Thus most of the 
IPA symbol names were taken from \cite{PullumLadusaw1986} \citep[31]{IPA1999}.

The working group insightfully decided that the computing-coding convention 
for the IPA should be independent of computer environments or formats (e.g.\ ASCII), 
i.e.\ the IPA Number was not meant to be implemented directly in a computer 
encoding. The working group report's declaration includes the explanatory 
remarks \citep[82]{International1989report}:

\begin{quote}
The recommendation of a 7-bit ASCII or 8-bit extended-ASCII coding system 
would be short-sighted in view of development towards 16-bit and 32-bit 
processors. In fact, any specific recommendations would tie the Association 
to a stage of technological development which is bound to be outdated long 
before the next revision of the handbook.
\end{quote}

\noindent Thus the coding convention was not meant to address the engineering 
aspects of the actual encoding in computers (cf.\ \cite{Anderson1984}). However, 
it was meant to serve as a basis for a communication-interchange standard for 
creating mapping tables from various computer encodings, fonts, phonetic-character-set 
software, etc., to common IPA Numbers, and thus symbols.\footnote{Remember, at 
this time in the late 1980s there was no stable multilingual computing environment. 
But some solution was needed because scholars were increasingly using personal 
computers for their research and many were quickly adopting electronic mail or 
discussion boards like Usenet as a medium for international exchanges. This was 
before the Internet as we know it today. Most of these systems ran on 8-bit 
hardware systems using a 7-bit ASCII character encoding.}

Furthermore, the assignment of computer codes to IPA symbols was meant to 
represent an unbiased formulation. The Association plays the role of an international 
advisory body and it stated that it should not recommend a particular existing 
system of encoding. In fact, during this time there were a number of coding 
systems used, but none of them had a dominant international position. The 
differences between systems were also either too great or too subtle to warrant 
an attempt at combining them \citep{International1989report}.

The working group assigned each IPA symbol to a unique three-digit number, 
i.e.\ an IPA Number. Encoded in this number scheme is information about the 
status of each symbol (see below). The IPA numbers are listed with the IPA 
symbols and they are also illustrated in IPA chart form (see \cite[84]{EslingGaylord1993} 
or \cite[App. 2]{IPA2007}). The numbers were assigned in linear order (e.g.\ 
[p] 101, [b] 102, [t] 103...) following the IPA revision of 1989 and its update in 1996.

The working group made the decision that no IPA symbol, past or present, 
could be ignored. The comprehensive inclusion of all IPA symbols was to 
anticipate the possibility that some symbols might be added, withdrawn, 
or reintroduced into current or future usage. For example, in the 1989 
revision voiceless implosives < ƥ, ƭ, ƈ, ƙ, ʠ > were added; in the 1993 
revision they were removed. Ligatures like < ʧ, ʤ > are included as formerly 
recognized IPA symbols; they are assigned to the ``200 series'' of IPA numbers 
as members of the group of symbols formerly recognized by the IPA. To ensure 
backwards compatibility, legacy IPA symbols would retain an IPA Number and 
an IPA Name for reference purposes. As we discuss below, this decision is 
later reflected in the Unicode Standard; many legacy IPA symbols reside in 
the \textsc{IPA Extensions} block.

The IPA Number is simply expressed as a ``three-digit number numerical 
directory of digit triples'' \cite{}.\footnote{For practical purposes, 
the IPA Number also served as a typesetter's guide to the IPA chart.} 
The numbering scheme specifies three-digit codes, the first digit of which 
indicates the symbol's category \cite{Esling1990,EslingGaylord1993}:

\begin{itemize}
	\item 100s for accepted IPA consonants
	\item 200s for former IPA consonants and non-IPA symbols
	\item 300s for vowels
	\item 400s for segmental diacritics
	\item 500s for suprasegmental symbols
	\item 600s-800s for future specifications
	\item 900s for escape sequences
\end{itemize}

After a symbol is categorized, it is assigned a number sequentially, 
e.g.\ [i] 301, [e] 302, [ɛ] 303. The system allows for the addition 
of new symbols within the various series by appending them, e.g. [ⱱ] 
184. Former or often used but non-IPA symbols for consonants, vowels 
and diacritics are numbered from x99 backwards. For example, the voiceless 
and voiced postalveolar affricates and fricatives < č, ǰ, š, ž > are 
assigned the IPA numbers 299, 298, 297 and 296, respectively, because 
they are not sanctioned IPA symbols.

The assignment of the IPA numbers to IPA symbols provided the basis for 
uniquely identifying the set of past and present IPA symbols as a type of 
computational representational standard of the IPA. Within each revision 
of the IPA, the coding defines a closed and clearly defined set of characters. 
The benefits of this standardization are clear in at least two ways: it is 
used in translation tables that reference ASCII representations of the IPA, 
and this early computational representation of the IPA became the basis for 
its inclusion into the Unicode Standard version 1.0.

\subsection{SAMPA and X-SAMPA}

True to the working group's aim, the IPA numbers provided a mechanism for 
a communication interchange standard for creating mapping tables to various 
computer encodings. For example, the IPA coding system was used as a mapping 
system in the creation of SAMPA \citep{Wells_etal1992}, an ASCII representation 
of the IPA symbols. 

For a long time, linguists, like all other computer users, were
limited to ASCII-encoded 7-bit characters, which only includes Latin characters,
numbers and some punctuation and symbols. Restricted to these standard character
sets that lacked IPA support or other language-specific graphemes that they
needed, linguists devised their own solutions.\footnote{Early work addressing
the need for a universal computing environment for writing systems and their
computational complexity is discussed in \citet{Simons1989}. A survey of
practical recommendations for language resources, including notes on encoding,
can be found in \citet{BirdSimons2003}} For example, some chose to represent
unavailable graphemes with substitutes, e.g.~the combination of <ng> to
represent <ŋ>. Tech-savvy linguists redefined selected characters from a
character encoding by mapping custom made fonts to specific code points.\footnote{For 
example, SIL's popular font SIL IPA 1990}. However,
one linguist's electronic text would not render properly on another linguist's
computer without access to the same font. Furthermore, if two character encodings
defined two character sets differently, then data could not be reliably and
correctly displayed. This is a commonly encountered example of the non-interoperability of
data and data formats.

One solution was the ASCII-ification of the IPA, which simply involved 
defining keyboard-able sequences as IPA symbol codings.\footnote{\cite{Wells1987} 
provides an in-depth description of IPA codings from country-to-country. 
Later ASCII-IPAs include Kirshenbaum (created in 1992 in a Usenet group and 
named after its lead developer who was at Hewlett-Packard Laboratories) and 
Worldbet (published in 1993 by \cite{Hieronymus1993}, who was at AT\&T Laboratories).} 
A successful effort was SAMPA (Speech Assessment
Methods Phonetic Alphabet), which was created between 1988--1991 in Europe to 
represent IPA symbols with ASCII
character sequences \citep{Wells1987,Wells_etal1992}, e.g. <p\textbackslash> 
for [ɸ]. SAMPA was developed by a group of speech scientists from nine countries 
in Europe and it constituted the ASCII-IPA symbols needed for phonemic transcription 
of the principal European Union languages \citep{Wells1995}. It is still widely 
used in language technology.

Two problems with SAMPA are that (i) it is only a partial encoding of the IPA and (ii) it encodes different
languages in separate data tables, instead of using a universal alphabet, like
IPA.\@ SAMPA tables were developed as part of a European Commission-funded project to
address technical problems like electronic mail exchange (what is now simply
called email). SAMPA is essentially a hack to work around displaying IPA
characters, but it provided speech technology and other fields a basis that has
been widely adopted and often still used in code. So, SAMPA is a collection of tables to be
compared, instead of a large universal table representing all languages. 

An extended version of SAMPA, called X-SAMPA, set out to include every symbol, 
including all diacritics, in the IPA chart \citep{Wells1995}. X-SAMPA is considered
more universally applicable because it consists of one table that encodes all
characters in IPA. In line with the principles of the IPA, SAMPA and X-SAMPA include a 
repertoire of symbols. These symbols are intended to represent phonemes rather than 
all allophonic distinctions. Additionally, both ASCII-ifications of IPA are useful because 
strings of SAMPA or X-SAMPA are (reportedly) uniquely parsable \citep{Wells1995}. However, 
like the IPA, X-SAMPA has different notations for encoding the same phonetic phenomena 
(see Pitfall \ref{}).

SAMPA and X-SAMPA have been widely used for speech technology and as an encoding system in
computational linguistics. In fact, they are stilled used in popular software packages 
that require ASCII input and some of which have been co-opted for linguistic analyses, 
e.g.~RuG/L04 and SplitsTree4.\footnote{See \url{http://www.let.rug.nl/kleiweg/L04/} and 
\url{http://www.splitstree.org/}, respectively}


\subsection{The need for a single multilingual environment}

During the 1980's, it became increasingly clear that an adequate solution 
to the problem of multilingual computing environments was needed. Linguists 
were on the forefront of addressing this issue because they faced these 
challenges head-on by wishing to publish and communicate electronic text 
with phonetic symbols which were not included in basic ASCII.\footnote{One 
only needs to look at facsimiles of older electronic documents to see exotic 
symbols written in by hand.}

Long familiar were linguists already with the distinction between function 
and form. Even in the context of the computer implementation of writing systems, 
the necessity to distinguish form and function had been made \citep{Becker1984}. 
The computer industry, on the other hand, did not consider, ignored, or simply 
did not encode this principle when creating operating systems like MS-DOS, which 
were limited to 256 code points (due to computer hardware architecture) and 
encoded with one-to-one mappings from character codes to graphemes.

Industry was starting to tackle the issues involved in developing a single 
multilingual computing environment on a variety of fronts, including the then 
new technology of bitmap fonts and the creation of Font Manager and Script 
Manager by Apple \citep{Apple1985,Apple1986,Apple1988}. As noted above, around 
this time linguists were developing work-arounds such as SAMPA, so that they 
could communicate IPA transcription and use ASCII-based software. Some linguists 
formalized the issues of multilingual text processing from a computational 
perspective \citep{Anderson1984,Becker1984,Simons1989}. The study of writing 
systems was also being invigorated by the computational challenges in making 
computers work in a multilingual environment.\footnote{\cite[11--15]{Sampson1985} 
urges linguists to view the study of writing systems as legitimate scientific enquiry.}

% This standard became the basis for a proposal to include the IPA in the first version of the Unicode Standard. Decisions by the Computer Coding working group and work they continued after the 1989 Kiel Convention were adopted by the International Phonetic Association. These decisions are directly reflected in the Unicode Standard's encoding of IPA, seeing as it was the Association who submitted the script proposal to the Unicode Consortium.

The second major benefit of the standardization of the IPA in a computational 
representation by the Kiel working group is that it provided the basis for a 
formal proposal to be submitted to various international standards organizations, 
several of which were trying to tackle (and in a sense `win') the multilingual 
computing environment problem. Basically, everyone from corporations to governments 
to language scientists (for lack of a better term) wanted a single unified multilingual 
character encoding set for all the world's writing systems, even if they did not 
understand or appreciate the challenges involved in creating and adopting a solution. 
Additionally, advancements in computer hardware were making the solutions easier 
to implement in software.

The engineering problems and solutions had been spelled out years before, e.g.\ 
a two-byte encoding for multilingual text \citep{Anderson1984}. 
Although languages vary to an astounding extent (cf.\ \cite{EvansLevinson2009}), 
writing systems are quite similar formally and the issue of formal representation 
of the world's orthographic systems had also been addressed \citep{Simons1989}. 

A major obstacle in creating a single encoding multilingual environment from 
the perspective of writing systems involves the distinction between function 
and form \citep{Becker1984} This distinction is so central to basic linguistic 
theory and that trained linguists and semiologists take it as second nature. 
A central challenge in developing a universal character set was to combine a 
technological solution with a formalization of writing systems proper.\footnote{Of 
course there were additional practical issues to overcome, e.g.\ funding, creating 
the formal and technological proposal, deciding which characters and writing systems 
to include initially, while setting precedence of how to add new ones in the future.}

In hindsight it is easy to lose sight of how impactful 30 years of technological 
development have been on linguistics, from theory development using quantitative 
means to pure data collection and dissemination (which as fed back into the former). 
But at the end of the 1970s, virtually no ordinary working linguist was using a 
person computer \cite{Simons1996}. Personal computer usage, however, dramatically 
increased throughout the 1980s. By 1990, dozens of character sets were in common use. 
They varied in their architecture and in their character repertoires, which 
made things a mess. There were two major players in the universal character 
set race: Unicode and the International Organization for Standardization (ISO).

	
\subsection{Unicode and ISO 10646}

In the late 1980s, a universal character set was being developed by what 
is now referred to as the Unicode Consortium.\footnote{The Unicode 
Consortium was officially incorporated in January 1991.} This consortium 
consisted largely, although not entirely, of major US corporations, with 
the aim of overcoming the inoperability of different coded character sets 
and their costly hinderance for developing multilingual software development 
and for internationalization efforts. Commercial importance of course drove 
the early inclusion of Latin, non-Latin, and some exotic scripts; see the 
table of commercial importance as measured by GDP of countries using certain 
writing systems \citep[2]{unicode88}.

The original Unicode manifesto is \cite{unicode88.pdf}.\footnote{http://www.unicode.org/history/unicode88.pdf} 
Its aim was for a reliable international multilingual text encoding standard 
that would encompass all scripts of the world, or in the author's own words, 
``a new, world-wide ASCII''. An in-depth history of Unicode, highlighting 
interesting facts like its first text prototypes at Apple and its incorporation 
into TrueType, is retold online.\footnote{\url{http://www.unicode.org/history/earlyyears.html}}

Unicode 88 provided the basic principles for the Unicode Standard's design -- 
pushing for 16 bit representations of characters with a clear distinction 
between characters and glyphs. Some of the contents of this status proposal 
of 1988 were reworked for inclusion in the early Unicode Standard pre-publication 
drafts and by August 1990, the proposal was in a (very) rough draft format. Its 
editors and the Unicode Working Group (the predecessor to the Unicode Technical 
Committee) worked together to lay out the the proposed standard's structure and 
content. At this time, the proposal contained no code charts nor block descriptions. 

% http://www.unicode.org/history/earlyyears.html
% During this period of time, in addition to his co-authoring of Apple KanjiTalk, Davis was involved in further discussions of a universal character set which were being prompted by the development of the Apple File Exchange.

The other major player in developing a universal character set was the ISO 
working group from the International Standards Organization (ISO), based 
in Europe, which was responsible for ISO/IEC 10646. This character set 
standard was composed in 1989 and a draft was published in 1990.\footnote{\url{http://www.iso.org/iso/catalogue_detail.htm?csnumber=56921}} 
The `Universal Multiple-Octet Coded Character Set' or simply UCS was the first 
officially standardized character encoding with the aim of including all characters from all writing systems.\footnote{\url{http://www.nada.kth.se/i18n/ucs/unicode-iso10646-oview.html}}

ISO/IEC 10646 is partly based on ISO/IEC 8859, a series of of ASCII-based 
standard character encodings published in 1987 that use a single bit 8-byte 
character set. Each part of the standard, e.g.\ 8859-1, 8859-5, 8859-6, 
encodes characters to support different languages' writing systems, e.g.\ 
Latin-1 Western European, Latin/Cyrillic, Latin/Arabic, respectively. Being 
a joint effort by the International Organization for Standardization (ISO) 
and the International Electrotechnical Commission (IEC), the aim of the 
standard is reliable information exchange. So, again, issues of phonetic 
symbol encoding, typography, etc., were ignored -- or perhaps more properly 
put, not commercially driven at this early stage.

Intended for the major Western European languages, ISO/IEC 8859 was an 
extension of the ASCII character encoding standard, which included the 
English alphabet, numerals and computer control characters (e.g.\ beep, 
space, carriage return). By extending ASCII's 7-bit system to 8-bit, the 
character repertoire of each of ISO/IEC 8859 character set was doubled 
from 128 to 256 characters. Each character set defined a mapping between 
digital bit patterns and characters, which are visually rendered on screen 
as graphic symbols. ASCII was shared between ISO/IEC 8859 character sets, 
but the characters in the extra bit patterns were different. Thus an aim 
of the ISO working group responsible for ISO/IEC 10646 was to bring all 
characters in all writings systems into a single unified encoding.

In 1991, the Unicode Consortium and the ISO Working Group for ISO/IEC 10646 
decided to create a single universal standard for encoding multilingual text.\footnote{http://unicode.org/book/appC.pdf} 
The two character sets converged, resulting in mutually acceptable changes 
to both, and each group keeps versions of their respective character codes 
and encoding forms synchronized.\footnote{http://www.unicode.org/versions/} 
Although each standard has its own form of reference and the terminology in 
each may differ slightly, the practical difference is that the Unicode Standard 
is a formal implementation of ISO/IEC 10646 and imposes additional constraints 
on its implementation. The Unicode Standard includes character data, algorithms 
and specifications, outside the scope of ISO/IEC 10646, which ensure, when 
properly implemented in software applications and platforms, that characters 
are treated uniformly. 

The incorporation of the Unicode Standard into the international encoding 
standard ISO 10646 was approved by ISO as an International Standard in June 
1992.\footnote{http://www.unicode.org/versions/Unicode1.0.0/Notice.pdf} 
The joint Unicode and ISO/IEC 10646 standard has become \textit{the} universal 
character set and it is a single multilingual environment for the majority 
of the world's written languages. Its formal implementation has also been 
vital to the rise of a multi-lingual Internet.


\subsection{IPA and Unicode}

It was a long journey, but the goal of achieving a single multilingual 
computing environment has largely been accomplished. We users, however, 
must cope with the pitfalls that were dug along the way (see Pitfall sections below). 
Some linguists, including your humble authors, are particularly sensitive 
to these issues. So we provide practical advice and approaches in the rest 
of this chapter. But first, we explain how the IPA became incorporated 
into the Unicode Standard via ISO/IEC 10646.

% "The set of IPA symbols and their numbers were used to draw up an entity set within SGML by the Text Encoding Initiative (TEl). The name of each entity is formed by 'IPA' preceding the number, e.g. IPA304 is the rEIentity name of lower-case A. These symbols can be processed as IPA symbols and represented on paper and screen with the appropriate local font by modifying the :entity replacement text. The advantage of the SGML entity set is that it is independent or the character set being used."
% "A TEl writing system declaration (wsd) has been drawn up for the IPA symbols."
% A TEl writing system declaration (wsd) has been drawn up for the IPA symbols. This document gives information about the symbol and its IPA function, as well as its encoding in the accompanying SGML document and in UnicodelUCS and in AFII. The writing system declaration can be read as a text d9cument or processed by machines in an SMGL process.

After the Kiel Convention in 1989, the Computer Coding of the IPA working 
group assisted the International Phonetic Association in representing the 
IPA to ISO and to the Text Encoding Initiative (TEI) \citep{EslingGaylord1993}. 
The working group's formalization of the IPA, i.e.\ a full listing of agreed 
upon computer codings for phonetic symbols, was used in developing writing 
systems descriptions which were at the time being solicited for scripts to 
be included in initiatives for new multilingual international character 
encoding standards. The working group for ISO/IEC 10646 and Unicode were 
two such initiatives.

In the historical context of the IPA being considered for inclusion in 
ISO/IEC 10646, it is important to realize that there were a variety of 
sources (i.e.\ not just from the Association) which submitted character 
proposals for phonetic alphabets. These proposals, including from the 
Association via the Kiel working group, were considered as a whole by 
the ISO working groups which were responsible for incorporating a phonetic 
script into the universal character set (UCS). The ISO working groups that 
were responsible for assigning a phonetic character set then made their 
own submissions as part of a review process by ISO for approval based on 
both ``informatic'' and phonetic criteria \citep[86]{EslingGaylord1993}. 

Character set ISO/IEC 10646 was approved by ISO, including the phonetic 
characters submitted to them in May 1993. The set of IPA characters were 
assigned UCS codes in 16 bit representation (in hexadecimal) and were 
published Tables 2 and 3 in \cite{EslingGaylord1993}, which include a 
graphical representation of the IPA symbol, its IPA Name, phonetic description, 
IPA Number, UCS Code and AFII Code.\footnote{The Association for Font 
Information Interchange (AFII) was an international database of glyphs 
created to promote the standardization of font data required to produce 
ISO/IEC 10646.} Because the character sets of ISO/IEC 10646 and the 
Unicode Standard converged, the IPA as submitted by the Association 
and reviewed and further submitted by the ISO working group, was included 
in the Unicode Standard Version 1.0 -- largely as we know it today.\footnote{The 
Association later made the foresightful remark, ``When this character set 
is in wide use, it will be the normal way to encode IPA symbols.'' \citep[164]{IPA1999}.}

With subsequent revisions to the IPA, one might expect the Unicode 
Consortium would update the Unicode Standard in a way that is inline 
with linguists' or other language scientists' intuitions. However, 
updates that go against the ISO's and the Unicode Standard's principles 
of maintaining backwards compatibility lose out, i.e.\ it is more important 
to deal with the pitfalls created along the way then it is to change the 
standard. Therefore, many of the pitfalls we encounter when using Unicode 
IPA are historic relics that we have to come to grips with.

% https://en.wikipedia.org/wiki/Uralic_Phonetic_Alphabet
% http://www.unicode.org/conference/bulldog.html
% http://www-01.sil.org/computing/computing_environment.html

% ==========================
\section{Pitfall: No complete IPA code block}
\label{pitfall-no-complete-ipa-block}
% ==========================

The ambivalent nature of IPA glyphs arises because, on the one hand, the IPA
uses Latin-based glyphs like <a>, <b> or <p>. From this perspective, the IPA
seems to be just another orthographic tradition using Latin characters, all of
which do not get a special treatment within the Unicode Standard (just like
e.g.~the French, German, or Danish orthographic traditions do not have a special
status). On the other hand, the IPA uses many special symbols (like turned <ɐ>,
mirrored <ɘ> and/or extended <ɧ> Latin glyphs) not found in any other Latin-based
writing system. For this reason a special block with code points, called
\textsc{IPA Extensions} was already included in the first version of the Unicode
Standard (Version 1.0 from 1991).

As explained in Section~\ref{pitfall-blocks}, the Unicode Standard code space is
subdivided into character blocks, which generally encode characters from a
single script. However, as is illustrated by the IPA, characters that form a
single writing system may be dispersed across several different character
blocks. With its diverse collection of symbols from various scripts and
diacritics, the IPA is spread across 12 blocks in the Unicode
Standard:\footnote{This number of blocks depends on whether only IPA-sanctioned
symbols are counted or if the phonetic symbols commonly found in the literature
are also included, see~\cite[Appendix~C]{Moran2012}. The 159 characters from 12 
code blocks shown here are the characters proposed for ``strict'' IPA encoding, 
as discussed in Section~\ref{ipa-recommendations}.}

\begin{itemize}[itemsep=4pt]
	\item \textsc{Basic Latin }(27 characters) \newline 
	a b c d e f h i j k l m n o p q r s t u v w x y z~.~|
	\item \textsc{Latin-1 Supplement} (4 characters) \newline 
	æ ç ð ø
	\item \textsc{Latin Extended-A} (3 characters) \newline 
	ħ ŋ œ
	\item \textsc{Latin Extended-B} (4 characters) \newline 
	ǀ ǁ ǂ ǃ
	\item \textsc{Latin Extended-C} (1 character): \newline
	\charis{ⱱ}
	\item \textsc{IPA Extensions} (67 characters) \newline 
	ɐ ɑ ɒ ɓ ɔ ɕ ɖ ɗ ɘ ə ɛ ɜ ɞ ɟ ɠ ɡ ɢ ɣ ɤ ɥ ɦ ɧ ɨ ɪ ɬ ɭ ɮ ɯ ɰ ɱ ɲ ɳ ɴ \newline
	ɵ ɶ ɸ ɹ ɺ ɻ ɽ ɾ ʀ ʁ ʂ ʃ ʄ ʈ ʉ ʊ ʋ ʌ ʍ ʎ ʏ ʐ ʑ ʒ ʔ ʕ ʘ ʙ ʛ ʜ ʝ ʟ ʡ ʢ 
	\item \textsc{Greek and Coptic} (3 characters) \newline 
	β θ χ
	\item \textsc{Spacing Modifier Letters} (17 characters) \newline
	\dia{02DE} \dia{02E1} \dia{02B7} \dia{02B2} \dia{02E0} \dia{02E4} 
	\dia{02B0} \dia{02BC} \dia{02D0} \dia{02D1} ˥ ˦ ˧ ˨ ˩ {\large ˈ ˌ}
	\item \textsc{Superscripts and Subscripts} (1 character) \newline
	\dia{207F} 
	\item \textsc{Combining Diacritical Marks} (25 characters) \newline 
	\dia{033C} \dia{032A} \dia{033B} \dia{033A} \dia{031F} \dia{0320} \dia{031D} 
	\dia{031E} \dia{0318} \dia{0319} \dia{031C} \dia{0339} \dia{032C} \dia{0325} 
	\dia{0330} \dia{0324} \dia{0329} \dia{032F} \dia{0334} \dia{0303} \dia{0308} 
	\dia{033D} \dia{0306} \dia{031A} \ \dia{0361}{\large\fontspec{CharisSIL}◌}
    \item \textsc{General Punctuation} (2 characters) \newline 
    ‖ \charis{‿}
%	\item \textsc{Modifier Tone Letters} (2 characters) \newline
%	{\large\fontspec{CharisSIL}ꜛ ꜜ}
	\item \textsc{Arrows} (4 characters) \newline 
	↑ ↓ ↗ ↘

\end{itemize}

% ==========================
\section{Pitfall: IPA homoglyphs in Unicode}
\label{pitfall-ipa-homoglyphs}
% ==========================

Another problem is the large number of homoglyphs, i.e.~different characters
that have highly similar glyphs (or even completely identical glyphs, depending
on the font rendering). For example, a user of a Cyrillic computer keyboard
should ideally not use the <а> \textsc{cyrillic small letter a} at code point
\uni{0430} for IPA transcriptions, but instead use the <a> \textsc{latin small
letter a} at code point \uni{0061}, although visually they are mostly
indistinguishable, and the Cyrillic character is more easily typed on a Cyrillic
keyboard. Some further problematic homoglyphs related to encoding IPA in the
Unicode Standard are the following.

\begin{itemize}

  \item The uses of the apostrophe has led to long discussions on the Unicode
        Standard email list. An English keyboard inputs the symbol
        <\dia{0027}> \textsc{apostrophe} at \uni{0027}, although the preferred Unicode
        apostrophe is the <\dia{2019}> \textsc{right single quotation mark} at
        \uni{2019}.\footnote{Note that many word processors (like Microsoft
        Word) by default will replace straight quotes by curly quotes,
        depending on the whitespace around it.} However, the glottal
        stop/glottalization/ejective marker is yet another completely different
        character, namely <\dia{02BC}>, i.e.~the \textsc{modifier letter apostrophe} 
        at \uni{02BC}, which unfortunately looks mostly extremely similar to
        \uni{2019}. 
  \item Another problem is the <\dia{02C1}> \textsc{modifier letter reversed glottal
        stop} at \uni{02C1} vs.\@ the <\dia{02E4}> \textsc{modifier letter small reversed
        glottal stop} at \uni{02E4}. Both appear in various resources
        representing phonetic data online. This is thus a clear example for
        which the Unicode Standard does not solve the linguistic standardization
        problem.
  \item Linguists are also unlikely to distinguish between the <ə>
        \textsc{latin small letter schwa} at code point \uni{0259} and <ǝ>
        \textsc{latin small letter turned e} at \uni{01DD}.
  \item The alveolar click <ǃ> at \uni{01C3} is of course often simply
        typed as <!> \textsc{exclamation mark} at \uni{0021}.\footnote{In the
        Unicode Standard the <ǃ> at \unif{01C3} is labeled \textsc{latin letter
        retroflex click}, but in IPA that glyph is used for an alveolar or
        postalveolar click (not retroflex). This naming is probably best seen as
        an error in the Unicode Standard. For the ``real'' retroflex click, see 
        Section~\ref{ipa-additions}.}
  \item The dental click <ǀ>, in Unicode known as \textsc{latin letter dental
        click} at \uni{01C0}, is often simply typed as <|> \textsc{vertical
        line} at \uni{007C}.
  \item For the marking of length there is a special Unicode characters, namely
        <\dia{02D0}> \textsc{modifier letter triangular colon} at \uni{02D0}. However,
        typing <\dia{003A}> \textsc{colon} at \uni{003A} is of course much easier.        
  
\end{itemize} 


Conversely, non-linguists are unlikely to distinguish any semantic difference
between an open back unrounded vowel <ɑ> \textsc{latin small letter alpha} at
\uni{0251}, and the open front unrounded vowel <a> \textsc{latin small letter a}
at \uni{0061}, basically treating them as homoglyphs, although they are
different phonetic symbols. But even among linguists this distinction leads to
problems. For example, as pointed out by \citet{Mielke2009}, there is a problem
stemming from the fact that about 75\% of languages are reported to have a
five-vowel system \citep{Maddieson1984}. Historically, linguistic descriptions
tend not to include precise audio recording and measurements of formants, so
this may lead one to ask if the many <a> characters that are used in
phonological description reflects a transcriptional bias. The common use of <a>
in transcriptions could be in part due to the ease of typing the letter on an
English keyboard (or for older descriptions, the typewriter). We found it to be
exceedingly rare that a linguist uses <ɑ> for a low back unrounded
vowel.\footnote{One example is \citet[75]{Vidal2001a}, in which the author
states: ``The definition of Pilagá /a/ as [+back] results from its behavior in
certain phonological contexts. For instance, uvular and pharyngeal consonants
only occur around /a/ and /o/. Hence, the characterization of /a/ and /o/ as a
natural class of (i.e., [+back] vowels), as opposed to /i/ and /e/.''} They
simply use <a> as long as there is no opposition to <ɑ>.

%\footnote{See Thomason's Language Log post, ``Why I don't love the International Phonetic Alphabet'' at:\url{http://itre.cis.upenn.edu/~myl/languagelog/archives/005287.html}.}

Making things even more problematic, there is an old typographic tradition that
the double-story <a> uses a single-story <ɑ> in italics. This leads to the
unfortunate effect that even in many well-designed fonts the italics of <a> and
<ɑ> use the same glyph. For example, in Linux Libertine (the font of this book)
the italics of these characters are highly similar <\textit{a}> and
<\textit{ɑ}>, while in Charis SIL they are identical: <\textit{\charis{a}}> and
<\textit{\charis{ɑ}}>. If this distinction has to be kept upright in italics,
the only solution we can currently offer is to use \textsc{slanted} glyphs
(i.e.~artificially italicized glyphs) instead of real italics (i.e.~special
italics glyphs designed by a typographer).\footnote{For example, the widely used
IPA font Doulos SIL
(\url{http://scripts.sil.org/cms/scripts/page.php?item\_id=DoulosSIL}) does not
have real italics. This leads some word-processing software, like Microsoft
Word, to produce slanted glyphs instead. That particular combination of font and
software application will thus lead to the desired effect distinguishing <a>
from <ɑ> in italics. However, note that when the text is transferred to another
font (i.e.~one that includes real italics) and/or to another software
application (like Apple Pages, which does not perform slanting), then this
visual appearance will be lost. In this case we are thus still in the
pre-Unicode situation in which the choice of font and rendering software
actually matters. The ideal solution from a linguistic point of view would be
the introduction of a new IPA code point for a different kind of <a>, which
explicitly specifies that it should still be rendered as a double-story
character when italicized. After informal discussion with various Unicode
players, our impression is that this highly restricted problem is not
sufficiently urgent to introduce even more <a> homographs in Unicode (which
already lead to much confusion, see Section~\ref{pitfall-homoglyphs}).}

% ==========================
\section{Pitfall: Homoglyphs in IPA}
\label{pitfall-homoglyphs-in-IPA}
% ==========================

Reversely, there are a few cases in which the IPA distinguishes different
phonetic concepts, but the visual characters used by the IPA look very much
alike. Such cases are thus homoglyphs in the IPA itself, which of course need
different encodings.

\begin{itemize}
  
   \item The dental click <ǀ> and the indication of a minor group break <|>
           look almost the same in
           most fonts. For a proper encoding, the \textsc{latin letter dental
           click} at \uni{01C0} and the \textsc{vertical line }at \uni{007C} 
           should be used, respectively.
   \item Similarly, the alveolar lateral click <ǁ>	should be encoded with a
           \textsc{latin letter lateral click} at \uni{01C1}, different from <‖>, 
           which according to the IPA is the character to by used for a major group 
           break (by intonation), to be encoded by \textsc{double vertical line} 
           at \uni{2016}.
   \item The marking of primary stress < ˈ > looks like an apostrophe, and
           is often typed with the same symbol as the ejective <\dia{02BC}>. For a
           proper encoding, these two symbols should be typed as 
           \textsc{modifier letter vertical line} at \uni{02C8} and
           \textsc{modifier letter apostrophe} at \uni{02BC}, respectively. 
   \item There are two different ``dashed''-l characters in IPA, namely the <ɫ> 	      \textsc{latin small letter l with middle tilde} at \uni{026B} and the <ɬ>	      \textsc{latin small letter l with belt} at \uni{026C}. These of course
          look highly similar, although they are different sounds. As a solution, 
          we will actually propose to not use the middle tilde at all 
          (see Section~\ref{pitfall-multiple-options-ipa}).     
   
\end{itemize}

% ==========================
\section{Pitfall: Multiple encoding options in IPA}
\label{pitfall-multiple-options-ipa}     
% ========================== 

It is not just the Unicode Standard that offers multiple options for encoding
the IPA.\@ Even the IPA specification itself offers some flexibility in how
transcriptions have to be encoded. There are a few cases in which the IPA
explicitly allows for different options of transcribing the same phonetic
content. This is understandable from a transcriber's point of view, but it is
not acceptable when the goal is interoperability between resources written in
IPA.\@ We consider it crucial to distinguish between ``lax'' IPA, for which it
is sufficient that any phonetically-trained reader is able to understand the
transcription, and ``strict'' IPA, which should be standardized on a single
unique encoding for each sound, so search will work across resources. We are
aware of the following non-unique encoding options in the IPA, which will be
discussed in turn below:

\begin{itemize}
  \item The marking of tone
  \item The marking of <g>
  \item The marking of velarization and pharyngealization
  \item The placement of diacritics
\end{itemize}

The first case in which the IPA allows for different encodings is the question
of how to transcribe tone. There is an old tradition to use diacritics on vowels
to mark different tone levels, e.g. <ȅèée̋>.\footnote{To make things even more
complex, there are at least two different Unicode homoglyphs for the low and
high level tones, namely <\diaf{0340}> \textsc{combining grave tone mark} at
\unif{0340} vs.~<\diaf{0300}> \textsc{combining grave accent} at \unif{0300} for
low tone, and <\diaf{0341}> \textsc{combining acute tone mark} at \unif{0341}
vs.<\diaf{0301}> \textsc{combining acute accent} at \unif{0301} for high tone.}
The IPA also proposes the option of tone letters, e.g. <˥˦˧˨˩>, which are much
less often used, but are more consistent for contours. Tone letters in the IPA
have five different levels, and sequences of these letters can be used to
indicate contours. Well-designed fonts will even merge a sequence of tone
letters into a contour. For example, compare the font Linux Libertine, which
does not merge tone letters <{\fontspec{LinLibertineO}˥˨˧˩}>, with the font
CharisSIL, which merges this sequence of four tone letters into a single contour
<\charis{˥˨˧˩}>. For strict IPA encoding we propose to standardize on tone
letters.

% IPA1999 pg 19
% "Either of the variant letter shapes [g] and [g] may be used to represent the voiced velar plosive."

Second, we commonly encounter the use of <g> \textsc{latin small letter g} at
\uni{0067}, instead of the Unicode Standard IPA character for the voiced velar
stop <ɡ> \textsc{latin small letter script g} at \uni{0261}. One begins to
question whether this issue is at all apparent to the working linguist, or if
they simply use the \uni{0067} because it is easily keyboarded and thus saves
time, whereas the latter must be cumbersomely inserted as a special symbol in
most software. The International Phonetic Association has taken the stance that
both the keyboard \textsc{latin small letter g} and the \textsc{latin small
letter script g} are valid input characters for the voiced velar plosive.
Unfortunately, this decision further introduces ambiguity for linguists trying
to adhere to a strict Unicode Standard IPA encoding. For strict IPA encoding we
propose to standardize on the more idiosyncratic \textsc{latin small letter
script g} at \uni{0261}.

Third, the IPA has special markers for velarization <\dia{02E0}> and
pharyngealization <\dia{02E4}>. Confusingly, there is also a marker for
``velarized or pharyngealized'', using the <\dia{0334}> \textsc{combining tilde
overlay} at \uni{0334}. The tilde overlay seems to be extremely rarely used. We 
suggest to try and avoid using the tilde overlay, though for reasons of backward 
compatibility we will allow it in strict-IPA.\@

Finally, the IPA states that ``diacritics may be placed above a symbol with a
descender''. For example, for marking marking of voiceless pronunciation of
voiced segments the IPA uses the ring diacritic. Originally, the ring should be
placed below the base character, like in <m̥>, using the \textsc{combining ring
below} at \uni{0325}. However, in letters with long descenders the IPA also
allows to put the ring above the base, like in <ŋ̊>, using the \textsc{combining
ring above} at \uni{030A}. Yet, proper font design does not have any problem
with rendering the ring below the base character, like in <ŋ̥>, so for strict
IPA encoding we propose to standardize on the ring below. As a principle, for
strict IPA encoding only one options should be allowed for all diacritics.

The variable encoding as allowed by the IPA becomes even more troublesome for
the tilde and diaeresis diacritics. In these cases, the IPA itself attaches
different semantics to the symbols above and below a base characters. The tilde
above a character (like in <ã>, using the \textsc{combining tilde} at
\uni{0303}) is used for nasalization, while the tilde below a character (like in
<a̰>, using the \textsc{combining tilde below} at \uni{0330}) indicates creaky
voice. Likewise, the diaeresis above (like in <ä>, using the \textsc{combining
diaeresis} at \uni{0308}) is used for centralization, while the diaeresis below
a character (like in <a̤>, using the \textsc{combining diaeresis below} at
\uni{0324}) indicates breathy voice. These cases strengthen our plea to not
allow diacritics to switch position for typographic convenience.

% length IPA 1999:22
% "Note: as in Finnish orthography, length can also be indicated in phonetic transcription by double letters: e.g . Finnish maatto [rncctto] 'electrical earth/ground'."

% syllable breaks and word boundaries <\s, ., |, ||, tie-bar below>
% White spaces can be used to indicate word boundaries. Syllable breaks can be marked when required. The other two boundary symbols are used to mark the domain of larger prosodic units. There is also a linking symbol that can be used for explicitly indicating the lack of a boundary.

%  (In all these transcriptions, no spaces between words have been included. This is inevitable in an impressionistic transcription where it is not yet known how the utterance divides into words. In phonemic and allophonic transcriptions it is common to include spaces to aid legibility, but their theoretical validity is problematic.)


% ==========================
\section{Pitfall: Tie bar}
\label{pitfall-tie-bar}
% ==========================

% Wells1995:10 "The underscore could in principle also be pressed into service to represent the IPA tie bar. The current chart mentions its use only for affricates and double articulations, and then only "if necessary"."

In the major revision of the IPA in 1932, affricates were represented by two consonants 
(e.g.\ <tʃ>), or ligatures <ʧ>, or with the tie-bar <t͡ʃ>. In the 1938 revision the tie-bar's 
semantics were broadened to indicate simultaneous articulation, e.g.\ in labial velars 
such as <k͡p>. Thus the tie-bar is a convenient diacritic for visually tokenizing input 
strings into chunks of phonetically salient groups, including affricates, doubly articulated 
consonants or diphthongs. 

The tie bar can be placed above or below the base characters, e.g. <\charis{t͡s}>
or <\charis{t͜s}>.\footnote{Note that the \textsc{undertie} at \uni{203F} symbol 
looks like and is easily confused with the tie-bar below. However, it is a different 
character and has a different function in IPA. The undertie is used as a linking 
symbol to indicate the lack of a boundary, e.g.\ petit ami [pətit‿ami] `boyfriend' 
($<$ French).} IPA allows both options. The choice between the two symbols
is purely for legible rendering; there is no difference in semantics between the
two symbols. However, rendering is such a problematic issue for tie bars in
general that many linguists simply do not use them. Just looking at a few
different fonts already indicates that actually no font designer really gets the
placement right in combination with superscripts and subscripts. If really
necessary, we propose to standardize on the tie bar above the base characters,
using a \textsc{combining double inverted breve} at \uni{0361}.

\begin{itemize}[itemsep=6pt]
  \item[] {\fontspec{Times New Roman}Times new Roman: t̥ʰ͡s t̥ʰ͜s}
  \item[] {\small \fontspec{CharisSIL}CharisSIL:\@ t̥ʰ͡s t̥ʰ͜s}
  \item[] {\footnotesize \fontspec{Monaco}Monaco: t̥ʰ͡s t̥ʰ͜s}
  \item[] {\fontspec{DoulosSIL}DoulosSIL:\@ t̥ʰ͡s t̥ʰ͜s}
  \item[] Linux Libertine: t̥ʰ͡s t̥ʰ͜s
\end{itemize}

Tie bars are a special type of character in the sense that they do not belong to
a segment, but bind two graphemes together. This actually turns out to be rather
different from Unicode conceptions. The Unicode encoding of this character
belong to the Combining Diacritical Marks, namely either \textsc{combining double
inverted breve} at \uni{0361} or \textsc{combining double breve below} at
\uni{035C}. Such a combining mark is by definition tied to the character in
front, but not the character following it. The Unicode treatment of this
character thus only partly corresponds to the IPA conception, which ideally
would have the tie bar linked both to the character in front and to the
character following. 

Further, according to the spirit of the IPA, it would also be possible to
combine more than two base characters into one tie bar, but this is not possible
with Unicode (i.e.~there is no possibility to draw a tie bar over three of four
characters). It is possible to indicate such larger groups by repeating the tie
bar, like for a triphthong <a͡ʊ͡ə> in the English word \textit{hour}. If really
necessary, we consider this possible, even though the rendering will never look
good. 

Most importantly though, in comparison to normal Unicode processing, the tie-bar
actually takes a reversed approach to complex graphemes. Basically, the Unicode
principle (see Section~\ref{pitfall-characters-are-not-graphemes}) is that fixed
sequences in a writing system have to be specified as ``tailored'' grapheme
clusters. In case the sequence is not a cluster, this has to be explicitly
indicated. IPA takes a different approach. In IPA by default different base
letters are not connected into larger clusters; only when it is specified in the
string itself (using the tie bar).



% ==========================
\section{Pitfall: Ligatures and digraphs}
\label{pitfall-ligatures-digraphs}     
% ==========================   

% TODO: link back to discussion on IPA principles and how ligatures got brought along historically

One important distinction to acknowledge is the difference between multigraphs
and ligatures. Multigraphs are groups of characters (in the context of IPA e.g.
<tʃ> or <ou>) while ligatures are single characters (e.g. <ʧ> \textsc{latin
small letter tesh digraph} at \uni{02A7}). Ligatures arose in the context of
printing easier-to-read texts, and are included in the Unicode Standard for
reasons of legacy encoding. However, their usage is discouraged by the Unicode
core specification. Specifically related to IPA, various phonetic combinations
of characters (typically affricates) are available as single code-points in the
Unicode Standard, but are designated \textsc{digraphs}. Such glyphs might be used by
software to produce a pleasing display, but they should not be hard-coded into
the text itself. In the context of IPA, characters like the following ligatures
should thus \emph{not} be used. Instead a combination of two characters is
preferred:
      
\begin{itemize} 
	\item[] <ʣ> \textsc{latin small letter dz digraph} at \uni{02A3} 
	  (use <dz>) 
    \item[] <ʤ> \textsc{latin small letter dezh digraph} at \uni{02A4}
      (use <dʒ>)
    \item[] <ʥ> \textsc{latin small letter dz digraph with curl} at \uni{02A5}
      (use <dʑ>)
    \item[] <ʦ> \textsc{latin small letter ts digraph} at \uni{02A6} 
      (use <ts>)
	\item[] <ʧ> \textsc{latin small letter tesh digraph} at \uni{02A7} 
	  (use <tʃ>) 
    \item[] <ʨ> \textsc{latin small letter tc digraph with curl} at \uni{02A8}
      (use <tɕ>)
   	\item[] <ʩ> \textsc{latin small letter feng digraph} at \uni{02A9}
	  (use <fŋ>) 
\end{itemize}

However, there are a few Unicode characters that are historically ligatures, but
which are today considered as simple characters in the Unicode Standard and thus
should be used when writing IPA, namely:

\begin{itemize}
	\item[] <ɮ> \textsc{latin small letter lezh} at \uni{026E} 
	\item[] <œ> \textsc{latin small ligature oe} at \uni{0153} 
	\item[] <ɶ> \textsc{latin letter small capital oe} at \uni{0276} 
	\item[] <æ> \textsc{latin small letter ae} at \uni{00E6} 
\end{itemize}

% ==========================
\section{Pitfall: Missing decomposition}
\label{pitfall-missing-decomposition}
% ==========================

Although many combinations of base character with diacritic are treated as
canonical equivalent with precomposed characters, there are a few combinations
in IPA that allow for multiple, apparently identical, encodings that are not
canonical equivalent (see Section~\ref{pitfall-canonical-equivalence}). The
following elements should not be treated as diacritics when encoding IPA in
Unicode: 
\begin{itemize}
  \item[] <{\fontspec{CharisSIL}{\large ◌}}\symbol{"0321}> \textsc{combining palatalized hook below} at \uni{0321}
  \item[] <{\fontspec{CharisSIL}{\large ◌}}\symbol{"0322}> \textsc{combining retroflex hook below} at \uni{0322}
  \item[] <\dia{0335}> \textsc{combining short stroke overlay} at \uni{0335}
  \item[] <\dia{0337}> \textsc{combining short solidus overlay} at \uni{0337}
\end{itemize} 

There turn out to be a lot of characters in the IPA that could be conceived as
using any of these elements, like <ɲ>, <ɳ>, <ɨ> or <ø>. However, all such
characters exist as well as precomposed combination in Unicode, and these
precomposed characters should preferably be used.\footnote{The IPA does not
describe any character for a voiced retroflex implosive, which would
transparently be \charis{ᶑ}. We propose to add this character to the IPA, see
Section~\ref{ipa-additions}.} When instead combinations of a base character with
diacritic are used, then these combinations are not canonical equivalent to the
precomposed combinations. This means that any search will not find both at the
same time.

A similar problem arises with the rhotic hook. There are two precomposed
characters in Unicode with a rhotic hook, which are not canonical equivalent 
with a combination of the vowel with a separately encoded hook:
\begin{itemize}
  \item[] <ɚ> \textsc{latin small letter schwa with hook} at \uni{025A}
  \item[] <ɝ> \textsc{latin small letter reversed open e with hook} at \uni{025D}
\end{itemize}
All other combinations of vowels with rhotic hooks will have to be made by using
<\dia{02DE}> \textsc{modifier letter rhotic hook} at \uni{02DE}, because there
is not complete set of precomposed characters with rhotic hooks. For that reason
we propose to not use the two precomposed characters with hooks mentioned above,
but always use the separate rhotic hook at \uni{02DE} in IPA.\@

A similar situation arises with <\dia{0334}> \textsc{combining tilde overlay} at
\uni{0334}. The main reason some phoneticians like to use this in IPA is to mark
the ``dark'' <l> in English codas, using the character <ɫ> \textsc{latin small
letter l with middle tilde} at \uni{026B}. This character is not canonically
equivalent to the combination <l> + <\dia{0334}>, so one of the two possible
encodings has to be chosen. Because the tilde overlay is described as a general
mechanism by the IPA, we propose to use the separated <\dia{0334}>
\textsc{combining tilde overlay} at \uni{0334}. However, note that phonetically 
this seems to be (almost) superfluous (see Section~\ref{pitfall-multiple-options-ipa}) 
and the typical usage in the form of <ɫ> is (almost) a homoglyph with <ɬ> (see 
Section~\ref{pitfall-homoglyphs-in-IPA}). For these reasons we suggest to try 
and avoid the tilde overlay.

Reversely, note that the <ç> \textsc{latin small letter c with cedilla} at
\uni{00E7} is canonically equivalent with <c> with <\dia{0327}>
\textsc{combining cedilla} at \uni{0327}, so it will be separated into two
characters by Unicode canonical decomposition, also if such a decomposition is
not intended in the IPA.\@ However, because of the nature of canonical
equivalence (see Section~\ref{pitfall-canonical-equivalence}), these two
encodings are completely identical in any computational treatment, so this
decomposition does not have any practical consequences.

% ==========================
\section{Pitfall: Different notions of diacritics}
\label{pitfall-different-notions-of-diacritics}
% ==========================

% TODO: this section is wrong wrt IPA diacritics and needs updating @SM

Another pitfall relates to the question of what are diacritics. The problem is that
the meaning of the term diacritics as used by the IPA is not the same as is used
in the Unicode Standard. Specifically, diacritics in the IPA-sense are either
so-called \textsc{combining diacritical marks} or \textsc{spacing modifier
letters} in the Unicode Standard. Crucially, Combining Diacritical Marks are by
definition combined with the character before them (to form so-called default
grapheme clusters, see Section~\ref{the-unicode-approach}). In contrast, Spacing
Modifier Letters are by definition \emph{not} combined into grapheme clusters
with the preceding character, but simply treated as separate letters. In the
context of the IPA, the following IPA-diacritics are actually Spacing Modifier
Letters in the Unicode Standard:

\begin{itemize}
  
	\item[] Length marks, namely: 
	\begin{itemize}
	  \item[] <\dia{02D0}> \textsc{modifier letter triangular colon} at \uni{02D0}
	  \item[] <\dia{02D1}> \textsc{modifier letter half triangular colon} at \uni{02D1}
	\end{itemize}
	 
	\item[] Tone letters, like: 
	\begin{itemize} 
	  \item[] <˥> \textsc{modifier letter extra-high tone bar} at \uni{02E5}
	  \item[] <˨> \textsc{modifier letter low tone bar} at \uni{02E8}
	  \item[] and others like this
	\end{itemize}
	
	\item[] Superscript letters, like:
	\begin{itemize}
	  \item[] <\dia{02B0}> \textsc{modifier letter small h} at \uni{02B0}
	  \item[] <\dia{02E4}> \textsc{modifier letter small reversed glottal stop} at \uni{02E4}
	  \item[] <\dia{207F}> \textsc{superscript latin small letter n} at \uni{207F}
	  \item[] and many more like this
	\end{itemize}
	
	\item[] The rhotic hook:\footnote{It is really unfortunate that the rhotic hook
         in Unicode is classified as a Spacing Modifier, and not as a Combining 
         Diacritical Mark. Although the rhotic hook is placed to the right of its 
         base character (and not above or below), it still is always connected 
         to the character in front, even physically connected to it. We cannot 
         find any reason for this treatment, and consider it an error in 
         Unicode. We hope it will be possible to change this classification in 
         the future.}
	\begin{itemize}
	  \item[] <\dia{02DE}> \textsc{modifier letter rhotic hook} at \uni{02DE}
	\end{itemize}
	
\end{itemize}

Although linguists might expect these characters to belong together with the
character in front of them, at least for <ʰ> \textsc{modifier letter small h} at
\uni{02B0} the Unicode Consortium's decision to treat it as a separate character
is also linguistically correct, because according to the IPA it can be used both
for aspiration (more precisely post-aspiration following the base character) and
pre-aspiration (preceding the base character). The default combination of Spacing Modifiers with
the preceding character can be specified in orthography profiles (see
Chapter~\ref{orthography-profiles}).

% ==========================
\section{Pitfall: No unique diacritic ordering}
\label{pitfall-no-unique-diacritic-ordering}
% ==========================

Also related to diacritics is the question of ordering. To our knowledge, the
International Phonetic Association does not specify a specific ordering for
diacritics that combine with phonetic base symbols; this exercise is left to the
reasoning of the transcriber. However, such marks have to be explicitly ordered
if sequences of them are to be interoperable and compatible computationally. An example is a
labialized aspirated alveolar plosive: <tʷʰ>. There is nothing holding linguists
back from using <tʰʷ> instead (with exactly the same intended meaning). However,
from a technical standpoint, these two sequences are different, e.g.~if both
sequences are used in a document, searching for <tʷʰ> will not find any
instances of <tʰʷ>, and vice versa. Likewise, a creaky voiced syllabic dental
nasal can be encoded in various orders, e.g. <n̪̰̩>, <n̩̰̪> or <n̩̪̰>.

\subsubsection*{Canonical combining classes}

In accordance with the absence of any specification of ordering in the IPA, the
Unicode Standard likewise does not propose any standardized orders. Both leave it
to the user to be consistent; this approach naturally invites inconsistency across 
different authored resources.

There is one aspect of ordering for which the Unicode Standard does present a
canonical solution. However, it is uncontroversial from a linguistic
perspective. Diacritics in the Unicode Standard (i.e.~Combining Diacritical
Marks, see above) are classified in Canonical Combining Classes. In practice,
the diacritics are distinguished by their position relative to the base
character.\footnote{See
\url{http://unicode.org/reports/tr44/\#Canonical\_Combining\_Class\_Values} for a
detailed description.} When applying a Unicode normalization (NFC or NFD, see
Section~\ref{pitfall-canonical-equivalence}), the diacritics in different
positions are put in a specified order. This process therefore harmonizes the
difference between different encodings, e.g.\ of an extra-short creaky voice
vowel <ḛ̆>. This grapheme cluster can be encoded either as
<e>+<\dia{0306}>+<\dia{0330}> or as <e>+<\dia{0330}>+<\dia{0306}>. To
prevent this twofold encoding, the Unicode Standard specifies the second
ordering as canonical (in this case, diacritics below are put before diacritics
above).

When encoding a string according to the Unicode Standard, it is possible to do
this either using the NFC (composition) or NFD (decomposition) normalization.
Decomposition implies that precomposed characters (like <á> \textsc{latin small
letter a with acute} at \uni{00E1}) will be split into its parts. This might
sound preferable for a linguistic analysis, as the different diacritics are
separated from the base characters. However, note that most attached elements
like strokes (e.g.~in the <ɨ>), retroflex hooks (e.g.~in <ʐ>) or rhotic hooks
(e.g.~in <ɝ>) will not be decomposed, but strangely enough a cedilla (like in
<ç>) will be decomposed (see Section~\ref{pitfall-missing-decomposition}). In
general, Unicode decomposition does not behave like a feature decomposition as
expected from a linguistic perspective. It is thus important to consider Unicode
decomposition only as a technical procedure, and not assume that it is
linguistically sensible.

\subsubsection*{Proposal for diacritic ordering}

Facing the problem of specifying a consistent ordering of diacritics while
developing a large database of phonological inventories from the world's
languages, \citet[540]{Moran2012} defined a set of diacritic ordering
conventions. The conventions are influenced by the linguistic literature, though
some ad-hoc decisions had to be taken given the vast variability of phonological
segments described by linguists. 

By Unicode Canonical Combining Classes, the diacritics on top of a character,
like <\dia{0334}> (Combining Class number 1), always come before diacritics
below (Combining Class number 220), which in turn always come before diacritics
above (Combining Class number 230), which in turn come before diacritics over
multiple characters like the tie bar <\dia{0361}{\large\fontspec{CharisSIL}◌}>
(Combining Class number 233). We follow this order, but add the other IPA
diacritics (which are not diacritics in the Unicode sense) between diacritics
below and the tie bar. Within all these classes of diacritics there is no canonical
ordering specified by Unicode, so we propose an explicit ordering here.

Starting with the diacritics below: if a character sequence contains more than
one diacritic below the base character, then the place features are applied
first (linguolabial, dental, apical, laminal, advanced, retracted), followed by
the manner features (raised, lowered, advanced and retracted tongue root), then
secondary articulations (more round, less round), laryngeal settings (creaky,
breathy, voiced, devoiced), and finally the syllabic or non-syllabic marker. So,
the order that is proposed is the following, where <\textbar{}> indicates
\textit{or} and <→> indicates \textit{precedes}. Note that the groups of
alternatives (as marked by <\textbar{}>) are supposed never to occur together
with the same base character. In effect, this represents yet another restriction
on possible diacritic sequences.

\begin{itemize}
	\item[] \textsc{Combining Diacritical Marks (below) ordering:}
	\begin{itemize}	
	  \item[→] linguolabial <\dia{033C}> \textbar{} dental <\dia{032A}> \textbar{} apical <\dia{033A}> \textbar{} laminal <\dia{033B}>
	  \item[→] advanced <\dia{031F}> \textbar{} retracted <\dia{0320}> 
	  \item[→] raised <\dia{031D}> \textbar{} lowered <\dia{031E}>
	  \item[→] advanced tongue root <\dia{0318}> \textbar{} retracted tongue root <\dia{0319}>
	  \item[→] more rounded <\dia{0339}> \textbar{} less rounded <\dia{031C}>
	  \item[→] creaky voiced <\dia{0330}> \textbar{} breathy voiced <\dia{0324}> \textbar{} voiced <\dia{032C}> \textbar{} voiceless <\dia{0325}>
	  \item[→] syllabic <\dia{0329}> \textbar{} non-syllabic <\dia{032F}>
	\end{itemize}
 \end{itemize}

\noindent Next, if a character sequence contains more than one diacritic above the base
character, we propose the following order:

\begin{itemize}
	\item[] \textsc{Combining Diacritical Marks (above) ordering:}
	\begin{itemize}
	  \item[→] nasalized <\dia{0303}>
	  \item[→] centralized <\dia{0308}> \textbar{} mid-centralized <\dia{033D}>
	  \item[→] extra short <\dia{0306}>
	  \item[→] no audible release <\dia{031A}\ >
 \end{itemize} \end{itemize}

\noindent Then, when a character sequence contains more than one character of the Spacing
Modifier Letters, these will be placed after all combining diacritic marks in the
following order:

\begin{itemize}
	\item[] \textsc{Spacing Modifier Letters ordering:}
	\begin{itemize}
	  \item[→] rhotic hook <\dia{02DE}>
	  \item[→] lateral release <\dia{02E1}> \textbar{} nasal release <\dia{207F}>
	  \item[→] labialized <\dia{02B7}>
	  \item[→] palatalized <\dia{02B2}>
	  \item[→] velarized <\dia{02E0}>
	  \item[→] pharyngealized <\dia{02E4}>
	  \item[→] aspirated <\dia{02B0}> \textbar{} ejective <\dia{02BC}>
	  \item[→] long <\dia{02D0}> \textbar{} half-long <\dia{02D1}>
	\end{itemize}
\end{itemize}

\noindent Finally, the tie bar follows at the very end of any such sequence:

\begin{itemize}
  \item[] \textsc{Tie bar:}
  \begin{itemize}
%    \item[→] tone letters <˥ ˦ ˧ ˨ ˩>
    \item[→] tie bar <\dia{0361}{\large\fontspec{CharisSIL}◌}>
  \end{itemize}
\end{itemize}

% ==========================
\section{Pitfall: Future revisions to the IPA}
\label{ipa-revisions}
% ==========================

With each revision of the IPA, many decisions need to be made by 
the Association as to which symbols should be added, removed or 
changed. (Perhaps that's why the IPA is updated infrequently.) 
For example, in the 1989 revision of the IPA at the Kiel Convention, 
changes to specific symbols (in previous charts) were debated and 
the Association's members certain decisions. The prevailing mood at 
the convention was not to change specific symbols unless a strong 
case was made \cite{Ladefoged1990a}. For example, two such decisions 
included \cite[62]{Ladefoged1990a}:

\begin{itemize}
	\item symbols for clicks were changed from < ʇ, ʖ, ʗ > and replaced by < ǀ, ǁ, ǃ > because the latter were the symbols used by nearly all Khoisanists and Bantuists
	\item the Americanist tradition of < š, ž, č, ǰ > were not adopted because the Association members at the convention ``were not sufficiently impressed by arguments ... to the effect that these sounds formed a natural class, and thus is would be appropriate to recognize this by maintaining a common aspect to their symbolism''
\end{itemize}

\noindent These decisions have practical consequences for transcribers 
of IPA, particularly those who wish to follow recommended practices of 
encoding electronic text in the Unicode Standard. For example, the Unicode 
Standard contains removed symbols as labels them as clicks, e.g. <ʇ> 
\textsc{latin small letter turned t} at U+0287 in the \textsc{IPA Extensions} 
block has the comment `dental click (sound of ``tsk tsk'')'. In this case, 
the IPA transcriber must know the status of click symbols in the current 
version of the IPA and then identify those characters within the Unicode Standard. 

The most controversial issue regarding symbols debated at the convention 
was the representation for voiceless implosives \cite[62]{Ladefoged1990a}. 
Recall the principles of the IPA outlined in Section \ref{the-international-phonetic-alphabet}, 
such as using distinct symbols for phonological contrast versus convenience of 
display in the chart, must be taken into account when arguing for or against 
the inclusion or deletion of IPA symbols in the IPA chart. Furthermore, the 
inclusion of deletion of symbols should incorporate the phonetic knowledge 
of the world's languages.

\cite{Ladefoged1990a} argued against the inclusion of these symbols < ƥ, ƭ, ƈ, ƙ, ʠ > 
voiceless implosives, noting that: they are not contrastive (e.g.\ in Mayan 
languages); there is no instrumental evidence supporting voiceless implosives 
in Africa; the sounds are sufficiently rare as to not need a whole new row 
of symbols in the chart. Ladefoged favored symbolizing the sounds using a 
voiceless diacritic ring below voiced implosives, e.g.\ <ɓ̥>.

Nevertheless, in the 1989 IPA chart there is indeed a row for implosives 
containing voiceless and voiced pairs.\footnote{https://en.wikipedia.org/wiki/File:IPA\_as\_of\_1989.png} 
But already in the next revision, in 1993 (with an update in 1996), the voiceless 
implosives were dropped. The implosives row from the IPA consonantal chart 
disappeared and voiced implosives were given a column in the non-pulmonic 
consonants table (which is still reflected in the latest revision to date, IPA 2005).

The Journal of the International Phonetic Association follows its own 
published standard for the IPA at the time of publication, even when it 
may conflict with the Association's principle of using different symbols 
for contrastive sounds and diacritics for phonetic variation. For example, 
in the case of voiceless implosives, \cite{McLaughlin2005} shows that 
Seereer-Siin (Niger-Congo; Atlantic; ISO 639-3: srr) has a phonologically 
contrastive set of voiced and voiceless implosive stops at the labial, 
coronal and palatal places of articulation. These symbols are transcribed 
in an \textit{Illustrations of the IPA} article in the IPA journal as 
< ɓ̥, ɗ̥, ʄ̥ >.\footnote{Note that the IPA chart states that diacritics 
can also be placed above a symbol, e.g.\ reportedly for legibility's 
sake < ɠ̥> vs < ɠ̊ >. This of course leads to the variability in encoding 
that we are trying to address on a computational level in this work. 
See Section \ref{}.}

The point of this pitfall is to highlight that revisions to the IPA will 
continue into the future, albeit they are infrequent. Nevertheless, 
given the Unicode Standard's principle of maintaining backwards compatibility 
(at all costs), transcribers and consumers of IPA cannot rely solely on 
remarks in the Unicode Standard to reflect current standard IPA usage. 
There is the possibility that at a later revision of the IPA, symbols that 
are not currently encoded in the Unicode Standard are added to the IPA -- 
although we think this is unlikely. 


\begin{comment}
\subsection{IPA (practical) extensions}

The IPA extensions cover speech sounds beyond the sound systems of the world's languages, including symbols for pathological speech and paralinguistic functions (e.g.\ Braille?).

- pathological speech
- paralinguistic functions (Braille?)

As noted in Section \ref{}, extensions to the IPA -- in particular ``large-scale'' extensions -- 

% Englebretson2009.pdf
http://www.ruf.rice.edu/~reng/englebretson2009.pdf

X-SAMPA was an ASCII transliteration and is still purposeful for several programs 

There is also the extensions of the IPA designed for disordered speech, although the symbols are occasionally used for transcribing phonetic detail in ``normal'' speech or also cross-linguistic rarities.\footnote{\url{http://phoible.github.io/conventions/}}


% Unicode has its own history; for a summary: \url{http://www.unicode.org/history/summary.html}

https://www.phon.ucl.ac.uk/home/wells/ipa-unicode.htm

Computer codes for phonetic symbols
EslingGaylord1993

\end{comment}


% ==========================
\section{Additions to the IPA}
\label{ipa-additions}
% ==========================

In the course of collecting a large sample of phoneme systems across the world's
languages \citep{Moran2012}, we found that in order to preserve distinctions
both within and across language descriptions, additions to the approved IPA
glyph set were needed. Wherever possible these additions were drawn from the
extIPA symbols for disordered
speech.\footnote{\textbf{Add better reference here: }\url{https://www.internationalphoneticassociation.org/sites/default/files/extIPAChart2008.pdf}}
This section describes our proposed additions to the IPA glyph set. These
additions are not part of the official IPA recommendations, so they should be 
used with care.

\begin{itemize}
  
\item \textsc{Retroflex click} \newline
      Retroflex clicks can be represented by <‼> \textsc{double exclamation
      mark} at \uni{203C}. Note that the (post-)alveolar click <ǃ> at \uni{01C3}
      is confusingly referred to as \textsc{latin letter retroflex click} in the
      Unicode standard, which is probably best seen as an error.
\item \textsc{Voiced retroflex implosive} \newline 
      Although the IPA includes a
      series of voiced implosives (marked with a hook on top, see
      Section~\ref{pitfall-missing-decomposition}), there is no voiced retroflex
      implosive. Following the spirit of the IPA, we propose to use <\charis{ᶑ}>
      \textsc{latin small letter d with hook and tail} at \uni{1D91} for this
      sound.
\item \textsc{Fortis/lenis} \newline
      Languages described as having a fortis/plain/lenis distinction that
      corresponds poorly with the traditional
      voiced/voiceless-unaspirated/voiceless-aspirated continuum can be marked
      using the voiceless glyph for the plain phoneme, and then 
      <\dia{0348}> \textsc{combining double vertical line below} at
      \uni{0348} to mark the fortis articulation, and/or <\dia{0349}>
      \textsc{combining left angle below} at \uni{0349} for the lenis
      articulation.
\item \textsc{Frictionalization} \newline 
      The diacritic <\dia{0353}>
      \textsc{combining x below} at \uni{0353} can be used to represent three
      types of frictionalized sounds: First, click consonants where the release
      of the anterior closure involves an ingressive ``sucking'' sound similar
      to a fricative, for example <kǃ͓ʰ>; second, ``frictionalized'' vowels
      (sounds that are phonologically vocalic, but with sufficiently close
      closures to create buzzing); and third, fricative sounds at places of
      articulation that do not have dedicated fricative glyphs, for example
      sounds with voiceless velar lateral frication, like <ʟ̥͓>.
\item \textsc{Derhoticization} \newline 
      For derhoticization we propose to use
      <\dia{032E}> \textsc{combining breve below} at \uni{032E}. 
      \textbf{WHAT EXACTLY IS THIS?}
\item \textsc{Coronal non-sibilant} \newline
      Languages described as having a sibilant/non-sibilant distinction among
      coronal fricatives and affricates can be handled using the subscript
      <\dia{0347}> \textsc{combining equals sign below} at \uni{0347} to mark
      the non-sibilant phoneme.
\item \textsc{Glottalization} \newline 
      Glottalized sounds can be indicated using
      <\dia{02C0}> \textsc{modifier letter glottal stop} at \uni{02C0}, unless
      it is clear that either ``ejective'' or ``creaky voicing'' are the
      intended sounds (in which cases the standard IPA diacritics should be
      used). Pre-glottalized sounds can be marked with
      <\diareverse{02C0}> to the left of the base
      glyph, for example <\charis{ˀt}>.
\item \textsc{Voiced pre-aspiration} \newline Voiced sounds having
      pre-aspiration can be marked with
      <\diareverse{02B1}> \textsc{modifier letter
      small h with hook} at \uni{02B1} to the left of the base glyph, for
      example <\charis{ʱd}>.
\item \textsc{Epilaryngeal phonation} \newline 
      There are some rare articulations that make
      use of an epilaryngeal phonation mechanism (e.g.,~the “sphincteric vowels”
      of~!Xóõ). To represent these vowels, we propose to use the modifier <\dia{1D31}>
      \textsc{modifier letter capital e} at \uni{1D31} to denote such sphincteric
      phonation.

\end{itemize}




% ==========================
\section{Recommendations}
\label{ipa-recommendations}
% ==========================

% Great quote for standardization -- last sentence(s) in Ladefoged 1990:552

Summarizing the pitfalls as discussed in this chapter, we propose to define 
three different IPA encodings: strict-IPA, valid-IPA and widened-IPA.\@ These 
three encodings are subsets of each other, i.e.~strict-IPA is more restricted 
than valid-IPA, which it turn is more restricted than widened-IPA.\@ Informally 
speaking, valid-IPA represents the current state of the IPA \citep{IPA2005}. 
Strict-IPA represents a more constrained version of IPA, while widened-IPA is a 
slightly extended version of IPA, allowing a few more symbols.

\ 

\noindent Strict-IPA encoding is supposed to be used when interoperability of
phonetic resources is intended. It is a strongly constrained subset of IPA
geared towards uniqueness of encoding. Ideally, for each transcription there
should be exactly one possible strict-IPA encoding. For each phonetic feature
there is only one possibility (see Section~\ref{pitfall-multiple-options-ipa})
and the IPA diacritics are forced into a canonical ordering (see
Section~\ref{pitfall-no-unique-diacritic-ordering}).

Valid-IPA does allow alternative symbols with the same phonetic meaning, as 
specified in the official IPA specifications. Also, valid-IPA does not enforce a 
specific ordering of diacritics, because the IPA does not propose any such 
ordering. This means that in valid-IPA the same phonetic intention can be 
encoded in multiple ways. This is sufficient for phonetically trained human 
eyes, but it is not sufficient for automatic interoperability.

Finally, widened-IPA includes a few more symbols which seem to be useful for
various special cases (see Section~\ref{ipa-additions}).

\ 

\noindent At the end of this chapter we have added a few longish tables summarizing all
159 different unicode codepoints that form the basis of strict-IPA encoding
(107 letters, 36 diacritics and 16 remaining symbols). Each of
these tables shows a typical glyph, and then lists the Unicode Codepoint,
Unicode Name and IPA description for each symbol. Further, there is a table with 
the additional options for valid-IPA and a table with the additional options for 
widened-IPA.\@

textbf{NOTE: I HAVE ADDED VARIOUS TONE DIACRITICS TO VALID-IPA THAT ARE NOT IN
THE OFFICIAL IPA SUMMARY. SHOULD THEY BE INCLUDED?}

\begin{itemize}[itemsep=6pt]

  \item \textsc{strict-IPA letters} \newline
        The 107 different IPA letters as allowed in strict-IPA encoding are
        listed in Table~\ref{tab:ipa_letters} starting on
        page~\pageref{tab:ipa_letters}.
  \item \textsc{strict-IPA diacritics} \newline The 36 different IPA diacritics and
        tone markers (both Unicode Modifier Letters and Combining Diacritical
        Marks) as allowed in strict-IPA encoding are listed in
        Table~\ref{tab:ipa_diacritics} starting on
        page~\pageref{tab:ipa_diacritics}.
  \item \textsc{strict-IPA remainders} \newline The 16 remaining IPA symbols
        (boundary, stress, tone letters and intonation markers) as allowed in strict-IPA
        encoding are listed in Table~\ref{tab:ipa_leftovers} on
        page~\pageref{tab:ipa_leftovers}.
  \item \textsc{valid-IPA additions} \newline The 16 additional symbols as allowed in
        valid-IPA encoding are listed in Table~\ref{tab:ipa_lax} on
        page~\pageref{tab:ipa_lax}.     
  \item \textsc{widened-IPA additions} \newline
        The 10 proposed additions to the IPA are listed in
        Table~\ref{tab:ipa_additions} on page~\pageref{tab:ipa_additions}.
  
\end{itemize}

\newpage
\input{tables/unicode_letters}
\input{tables/unicode_diacritics}
\input{tables/unicode_remaining}
\input{tables/unicode_valid}
\input{tables/unicode_additions}
