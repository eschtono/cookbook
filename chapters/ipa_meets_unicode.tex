\chapter{IPA meets Unicode}
\label{ipa-meets-unicode}

\section{The International Phonetic Alphabet (IPA)}
\label{the-international-phonetic-alphabet}

The International Phonetic Alphabet (IPA) is a common standard in linguistics to
transcribe sounds of spoken language into some Latin-based characters
\citep{IPA2005}. Although IPA is reasonably easily adhered to with pen and
paper, it is not trivial to encode IPA characters electronically. Early work
addressing the need for a universal computing environment for writing systems
and their computational complexity is discussed in \citet{Simons1989}. For a long
time, linguists (like all other computer users) were limited to ASCII-encoded
7-bit characters, which only includes Latin characters, numbers and some
punctuation and symbols. Restricted to these standard character sets that lacked
IPA support or other language-specific graphemes that they needed, linguists
devised their own solutions \citep{BirdSimons2003}. For example, some chose to
represent unavailable graphemes with substitutes, e.g.~the combination of <ng> to
represent <ŋ>. Tech-savvy linguists redefined selected characters from a character
encoding by mapping custom made fonts to those code points. However, one
linguist's electronic text would not render properly on another linguist's
computer without access to the same font. Further, if two character encodings
defined two character sets differently, then data could not be reliably and
correctly displayed. This is a common example of the non-interoperability of
data and data formats.

To alleviate this problem, during the late 1980s, SAMPA (Speech Assessment
Methods Phonetic Alphabet) was created to represent IPA symbols with 7-bit
printable ASCII character sequences, e.g. <p\textbackslash> for [ɸ]. Two
problems with SAMPA are that (i) it is only a partial encoding of the IPA and
(ii) it encodes different languages in separate data tables, instead of a
universal alphabet, like IPA. SAMPA tables are derived from phonemes appearing
in several European languages that were developed as part of a European
Commission-funded project to address technical problems like electronic mail
exchange (what is now simply called email). SAMPA is essentially a hack to work
around displaying IPA characters, but it provided speech technology and other
fields a basis that has been widely adopted and used in code. So, SAMPA was a
collection of tables to be compared, instead of a large universal table
representing all languages. An extended version of SAMPA, called X-SAMPA, set
out to include every symbol in the IPA chart including all diacritics
\citep{WellsND}. X-SAMPA was considered more universally applicable because it
consisted of one table that encoded the set of characters that represented
phones/segments in IPA across languages. SAMPA and X-SAMPA have been widely used
for speech technology and as an encoding system in computational linguistics.
Eventually, ASCII-encoding of the IPA became deprecated through the advent of
the Unicode Standard. Note however that many popular software packages used for
linguistic analyses still require ASCII input, e.g.~RuG/L04 and
SplitsTree4.\footnote{See \url{http://www.let.rug.nl/kleiweg/L04/} and
\url{http://www.splitstree.org/}, respectively}

There are a few pitfalls to be aware of when using the Unicode Standard
to encode IPA. As we have said before, from a linguistic perspective it might
look like the Unicode Consortium is making incomprehensible decisions, but it is
important to realize that the consortium has tried and is continuing to try to
be as consistent as possible across a wide range of use cases, and it does place
linguistic traditions above other orthographic possibilities. In general, we
strongly suggest linguists not to complain about any decisions in the Unicode
Standard, but to try and understand the rationale of the Unicode Consortium
(which in our experience is almost always well-conceived) and devise ways to
work with any unexpected behavior. Many of the current problems derive from the
fact that the IPA is clearly historically based on the Latin script, but
different enough from most other Latin-based writing systems to warrant special
attention. This ambivalent status of the IPA glyphs (partly Latin, partly
special) is unfortunately also attested in the treatment of IPA in the Unicode
Standard. In retrospect, it might have been better to consider the IPA (and
other transcription systems) to be a special or new kind of script within the
Unicode Standard, and treat the obvious similarity to Latin glyphs as a
historical relic. All IPA glyphs would then have their own code points, instead
of the current situation in which some IPA glyphs have special code points,
while others are treated as being identical to the regular Latin characters.
Yet, the current situation, however unfortunate, is unlikely to change, so as
linguists we will have to learn to deal with the specific pitfalls of IPA within
the Unicode Standard. In this section, we will describe these pitfalls in some
detail.

\section{Pitfall: No complete IPA code block}
\label{pitfall-no-complete-ipa-block}

The ambivalent nature of IPA glyphs arises because, on the one hand, the IPA
uses Latin-based glyphs like <a>, <b> or <p>. From this perspective, the IPA
seems to be just another orthographic tradition using Latin characters, all of
which do not get a special treatment within the Unicode Standard (just like
e.g.~the French, German, or Danish orthographic traditions do not have a special
status). On the other hand, the IPA uses many special symbols (like turned,
mirrored and/or extended Latin glyphs) not found in any other Latin-based
writing system. For this reason, and already in the first version of the Unicode
Standard (Version 1.0 from 1991), a special block with code points, called
\textsc{IPA Extensions} was included. 

As explained in Section~\ref{pitfall-blocks}, the Unicode Standard code space is
subdivided into character blocks, which generally encode characters from a
single script. However, as is illustrated by the IPA, characters that form a
single writing system may be dispersed across several different character
blocks. With its diverse collection of symbols from various scripts and
diacritics, the IPA is spread across 13 blocks in the Unicode
Standard:\footnote{This number of blocks depends on whether only IPA-sanctioned
symbols are counted or if the phonetic symbols commonly found in the literature
are also included, see \cite[Appendix C]{Moran2012}.}

\begin{itemize}
	\item Basic Latin (30 characters), e.g. <a b c d e> 
	\item Latin-1 Supplement (4 characters): <æ ç ð ø> 
	\item Latin Extended-A (3 characters): <ħ ŋ œ> 
	\item Latin Extended-B (5 characters): <ǀ ǁ ǂ ǃ ȵ> 
	\item IPA Extensions (70 characters), e.g. <ɐ ɑ ɔ> 
	\item Spacing Modifier Letters (20 characters), e.g. <ʰ ʷ ˥> 
	\item Combining Diacritical Marks (33 characters), e.g. <{\large \ \ ̝\ \ ̥\ \ ̪ }> 
	\item Greek and Coptic (3 characters): <β θ χ> 
	\item Phonetic Extensions (2 characters): <{\small \fontspec{CharisSIL}ᴅ ᴴ}> 
	\item Phonetic Extensions Supplement (3 characters): <{\small \fontspec{CharisSIL}ᶑ ᶾ ᶣ}> 
	\item Superscripts and Subscripts (1 character): <ⁿ> 
	\item Arrows (4 characters): <↑ ↓ ↗ ↘>
	\item Latin Extended-C (1 character): <{\small \fontspec{CharisSIL}ⱱ}> 
\end{itemize}

\section{Pitfall: IPA homoglyphs in Unicode}
\label{pitfall-ipa-homoglyphs}

Another problem is the large number of homoglyphs, i.e.~different characters
that have highly similar glyphs (or even completely identical, depending on the
font rendering). For example, a speaker of Russian should ideally not use the
<а> \textsc{cyrillic small letter a} at code point \uni{0430} for IPA
transcriptions, but instead use the <a> \textsc{latin small letter a} at code point
\uni{0061}, although visually they are mostly indistinguishable, and the
Cyrillic character is more easily typed on a Cyrillic keyboard. 

Furthermore, even linguists are unlikely to distinguish between
the <ə> \textsc{latin small letter schwa} at code point \uni{0259} and <ǝ>
\textsc{latin small letter turned e} at \uni{01DD}. Conversely,
non-linguists are unlikely to distinguish any semantic difference between an
open back unrounded vowel <ɑ> \textsc{latin small letter alpha} at
\uni{0251}, and the open front unrounded vowel <a> \textsc{latin small letter
a} at \uni{0061}. But even among linguists this distinction leads to problems.
For example, as pointed out by \citet{Mielke2009}, there is a problem stemming
from the fact that about 75\% of languages are reported to have a five-vowel
system \citep{Maddieson1984}. Historically, linguistic descriptions tend not to
include precise audio recording and measurements of formants, so this may lead
one to ask if the many characters that are used in phonological description
reflects a transcriptional bias. The common use of <a> in transcriptions
could be in part due to the ease of typing the letter on an English keyboard (or
for older descriptions, the typewriter). We found it to be exceedingly rare that
a linguist uses <ɑ> for a low back unrounded vowel.\footnote{One example is
\citet[75]{Vidal2001a}, in which the author states: ``The definition of Pilagá
/a/ as {[}+back{]} results from its behavior in certain phonological contexts.
For instance, uvular and pharyngeal consonants only occur around /a/ and /o/.
Hence, the characterization of /a/ and /o/ as a natural class of (i.e.,
{[}+back{]} vowels), as opposed to /i/ and /e/.''} They simply use <a> as
long as there is no opposition to <ɑ>.\footnote{See Thomason's Language Log
post, ``Why I don't love the International Phonetic Alphabet'' at:
\url{http://itre.cis.upenn.edu/~myl/languagelog/archives/005287.html}.}

Making things even more problematic, there is an old typographic tradition that
the double-story <a> uses a single-story <ɑ> in italics. This leads to the
unfortunate effect that in most well-designed fonts the italics of <a> and <ɑ>
use the same glyph. If this distinction has to be kept upright in italics, the
only solution we can currently offer is to use \textsc{slanted} glyphs
(i.e.~artificially italicized glyphs) instead of real italics (i.e.~special
italics glyphs designed by a typographer).\footnote{For example, the widely used
IPA font Doulos SIL
(\url{http://scripts.sil.org/cms/scripts/page.php?item\_id=DoulosSIL}) does not
have real italics. This leads some word-processing software, like Microsoft
Word, to produce slanted glyphs instead. That particular combination of font and
software application will thus lead to the desired effect distinguishing <a>
from <ɑ>. However, note that when the text is transferred to another font
(i.e.~one that includes real italics) and/or to another software application
(like Apple Pages, which does not perform slanting), then this visual appearance
will be lost. In this case we are thus still in the pre-Unicode situation in
which the choice of font and rendering software actually matters. The ideal
solution from a linguistic point of view would be the introduction of a new IPA
code point for a different kind of which explicitly specifies that it should
still be rendered as a double-story character when italicized. After informal
discussion with various Unicode players, our impression is that this highly
restricted problem is not sufficiently urgent to introduce even more <a>-like
characters in Unicode (which already lead to much confusion, see Section~\ref{pitfall-homoglyphs}).}

Some other homoglyphs related to encoding IPA in the Unicode Standard are:

\begin{itemize}
	\item The uses of the apostrophe has led to long discussions on the Unicode
       Standard email list. An English keyboard inputs <{\fontspec{Monaco}'}> \textsc{apostrophe}
       at \uni{0027}, although the preferred Unicode apostrophe is the <\ ' >
       \textsc{right single quotation mark} at \uni{2019}.
     \item The glottal stop/glottalization/ejective marker is another completely
        different character <{\large ʼ}>, the \textsc{modifier letter apostrophe} at
        \uni{02BC}, but unfortunately looks mostly highly similar to
        \uni{2019}. 
	\item Another problem is the <ˁ> \textsc{modifier letter reversed
       glottal stop} at \uni{02C1} vs.\@ the <ˤ> \textsc{modifier
       letter small reversed glottal stop} at \uni{02E4}. Both 
       appear in various resources representing phonetic data online. This is
       thus a clear example for which the Unicode Standard does not solve the
       linguistic standardization problem. 
	\item There is at least one case in which the character name assigned by the
       Unicode Consortium does not match the IPA's description. In the Unicode
       Standard the <ǃ> at \uni{01C3} is labeled \textsc{latin letter retroflex
       click}, but in IPA that glyph is used for an alveolar or postalveolar
       click (not retroflex). This naming is probably best seen as a simple
       error in the Unicode Standard. This character is of course often simply
       typed as <!> \textsc{exclamation mark} at \uni{0021}. \end{itemize}       

\section{Pitfall: Homoglyphs in IPA}
\label{pitfall-homoglyphs-in-IPA}

It is not just the Unicode Standard that offers multiple options for encoding
the IPA. Even the IPA specification itself offers some flexibility in how
transcriptions have to be encoded. There are a few cases in which the IPA
explicitly allows for different options of transcribing the same phonetic
content. This is understandable from a transcriber's point of view, but it is
not acceptable for interoperability between resources written in IPA. We
consider it crucial to distinguish between ``lax'' IPA, for which it is
sufficient that any phonetically-trained reader is able to understand the
transcription, and ``strict'' IPA, which should be standardized on a single
unique encoding for each sound, so search will work across resources. We are 
aware of the following double options in the IPA, which will be discussed in 
turn below:

\begin{itemize}
  \item The marking of tone
  \item The marking of <g>
  \item The diacritic for voiceless
  \item The tie bar to indicate a close bond between sounds
\end{itemize}

\ 

\noindent The first case in which the IPA allows for different encodings is the question
of how to transcribe tone. There is an old tradition to use diacritics on vowels
to mark different tone levels, e.g. <ȅèée̋>.\footnote{There are at least two
different Unicode homoglyphs for the low and high level tones, namely <\ ̀~>
\textsc{combining grave tone mark} at \unif{0340} vs.\@ <\ ̀~> \textsc{combining
grave accent} at \unif{0300} for low tone, and <\ ́~> \textsc{combining acute tone
mark} at \unif{0341} vs.\@ <\ ́~> \textsc{combining acute accent} at \unif{0301}
for high tone.} The IPA also proposes a less widespread used, but more
consistent option of tone letters, e.g. <˥˦˧˨˩>. Tone letters in the IPA have
five different levels, and sequences of these letters can be used to indicate
contours. Well-designed fonts will even merge a sequence of tone letters into a
contour. For example, compare the font Linux Libertine, which does not merge
tone letters <{\fontspec{LinLibertineO}˥˨˧˩}>, with the font CharisSIL, which
merges this sequence of four tone letters into a single contour <\charis{˥˨˧˩}>.
For strict IPA encoding we propose to standardize on tone letters.

Second, we commonly encounter the use of <g> \textsc{latin small letter g} at
\uni{0067}, instead of the Unicode Standard IPA character for the voiced velar
stop <ɡ> \textsc{latin small letter script g} at \uni{0261}. One begins to
question whether this issue is at all apparent to the working linguist, or if
they simply use the \uni{0067} because it is easily keyboarded and thus saves
time, whereas the latter must be cumbersomely inserted as a special symbol in
most software. This issue was recently addressed by The International Phonetic
Association has taken the stance that both the keyboard \textsc{latin small
letter g} and the \textsc{latin small letter script g} are valid input
characters for the voiced velar plosive. Unfortunately, this decision further
introduces ambiguity for linguists trying to adhere to a strict Unicode Standard
IPA encoding. For strict IPA encoding we propose to standardize on the more 
idiosyncratic \textsc{latin small letter script g} at \uni{0261}.

Third, for marking marking of voiceless pronunciation of voiced segments the IPA
uses the ring diacritic. Originally, the ring should be placed below the 
base character, like in <m̥>, using the \textsc{combining ring below} at \uni{0325}. 
However, in letters with long descenders the IPA also allows to put the ring 
above the base, like in <ŋ̊>, using the \textsc{combining ring above} at 
\uni{030A}. Yet, proper font design does not have any problem with rendering 
the ring below the base character, like in <ŋ̥>, so for strict IPA encoding we 
propose to standardize on the ring below.
 
Likewise, the tie bar to indicate affricates, doubly articulated consonants or
diphthongs can be placed either below or on top of the base characters, e.g.
<\charis{t͡s}> or <\charis{t͜s}>. For strict IPA encoding we propose to standardize on the tie bar
above the base characters, using Unicode \textsc{combining double inverted
breve} at \uni{0361}. Note that this Unicode character is placed between the two 
base characters to be combined. In principle, it is possible to combine more 
than two base characters by repeating the tie bar, like in <a͡o͡u>. If really
necessary, we consider this possible, even though the rendering will never look 
good.


\section{Pitfall: Ligatures and digraphs}
\label{pitfall-ligatures-digraphs}     
       
One important distinction to acknowledge is the difference between multigraphs
and ligatures. Multigraphs are groups of characters (in the context of IPA e.g.
<tʃ> or <ou>) while ligatures are single characters (e.g. <ʧ> \textsc{latin
small letter tesh digraph} at \uni{02A7}). Ligatures arose in the context of
printing easier-to-read texts, and are included in the Unicode Standard for
reasons of legacy encoding. However, their usage is discouraged by the Unicode
core specification. Specifically related to IPA, various phonetic combinations
of characters (typically affricates) are available as single code-points in the
Unicode Standard, but are designated as \textsc{ligatures} or \textsc{digraphs}
(confusingly both names appear interchangeably). Such glyphs might be used by
software to produce a pleasing display, but they should not be hard-coded into
the text itself. In the context of IPA, characters like the following ligatures
should thus \emph{not} be used. Instead a combination of two characters is
preferred:
      
\begin{itemize} 
	\item <ʣ> \textsc{latin small letter dz digraph} at \uni{02A3} 
	  (use <dz> instead) 
    \item <ʤ> \textsc{latin small letter dezh digraph} at \uni{02A4}
      (use <dʒ> instead)
    \item <ʥ> \textsc{latin small letter dz digraph with curl} at \uni{02A5}
      (use <dʑ>)
    \item <ʦ> \textsc{latin small letter ts digraph} at \uni{02A6} 
      (use <ts> instead)
	\item <ʧ> \textsc{latin small letter tesh digraph} at \uni{02A7} 
	  (use <tʃ> instead) 
    \item <ʨ> \textsc{latin small letter tc digraph with curl} at \uni{02A8}
      (use <tɕ>)
   	\item <ʩ> \textsc{latin small letter feng digraph} at \uni{02A9}
	  (use <fŋ> instead) 
\end{itemize}

However, there are a few Unicode characters that are historically ligatures, but
which are today considered as simple characters in the Unicode Standard and thus
should be used when writing IPA, namely:

\begin{itemize}
	\item <ɮ> \textsc{latin small letter lezh} at \uni{026E} 
	\item <œ> \textsc{latin small ligature oe} at \uni{0153} 
	\item <ɶ> \textsc{latin letter small capital oe} at \uni{0276} 
	\item <æ> \textsc{latin small letter ae} at \uni{00E6} 
\end{itemize}

\section{Pitfall: Missing decomposition}
\label{pitfall-missing-decomposition}

Although many combinations of base character with diacritic are treated as 
canonical equivalent with precomposed characters, there are a few combinations 
in IPA that allow for multiple, apparently identical, encodings that are not 
canonical equivalent. The following elements should not be treated as diacritics 
when encoding IPA in Unicode:
\begin{itemize}
  \item <\ {\large  ̡}\ > \textsc{combining palatalized hook below} at \uni{0321}
  \item <\ \ {\large  ̢}> \textsc{combining retroflex hook below} at \uni{0322}
  \item <\ \ {\large  ̵}> \textsc{combining short stroke overlay} at \uni{0335}
  \item <\ \ {\large  ̷}> \textsc{combining short solidus overlay} at \uni{0337}
  \item <\ \ {\large  ̴}> \textsc{combining tilde overlay} at \uni{0334}
  \item <{\large ˞}> \textsc{modifier letter rhotic hook} at \uni{02DE}
\end{itemize} 

There turn out to be a lot of characters in the IPA that could be conceived as 
using any of these elements, like <ɲ>, <ɳ>, <ɨ>, <ø>, <ɫ> or <ɚ>. However, all 
such characters exist as well as ``precomposed'' combination in Unicode, and these 
precomposed characters should preferably be used. When combinations of a base 
character with diacritic are used, then these combinations are not canonical 
equivalent to the precomposed combinations. This means that any search will not 
find both at the same time.

Reversely, <ç> \textsc{latin small letter c with cedilla} at \uni{00E7} will be
decomposed into <c> \textsc{latin small letter c} at \uni{0063} with 
<\ \ {\large  ̧}> \textsc{combining cedilla} at \uni{0327}, 
also if such a decomposition is not intended, because it is meaningless in IPA.

\section{Pitfall: Different notions of diacritics}
\label{pitfall-different-notions-of-diacritics}

Another pitfall relates the concept of what are diacritics. The problem is that
the meaning of the term diacritics as used by the IPA is not the same as is used
in the Unicode Standard. Specifically, diacritics in the IPA-sense are either
so-called \textsc{combining diacritical marks} or \textsc{spacing modifier
letters} in the Unicode Standard. Crucially, Combining Diacritical Marks are by
definition combined with the character before them (to form so-called default
grapheme clusters, see Section~\ref{the-unicode-approach}). In contrast, Spacing
Modifier Letters are by definition \emph{not} combined into grapheme clusters
with the preceding character, but simply treated as separate letters. In the
context of the IPA, the following IPA-diacritics are actually Spacing Modifier
Letters in the Unicode Standard:

\begin{itemize}
	\item[] Length marks, namely 
	\begin{itemize}
	  \item[] <ː> \textsc{modifier letter triangular colon} at \uni{02D0}
	  \item[] <ˑ> \textsc{modifier letter half triangular colon} at \uni{02D1}
	\end{itemize}
	 
	\item[] Tone letters, like 
	\begin{itemize} 
	  \item[] <˥> \textsc{modifier letter extra-high tone bar} at \uni{02E5}
	  \item[] <˧> \textsc{modifier letter mid tone bar} at \uni{02E7}
	  \item[] and others like this
	\end{itemize}
	
	\item[] Superscript letters, like 
	\begin{itemize}
	  \item[] <ʰ> \textsc{modifier letter small h} at \uni{02B0}
	  \item[] <ˤ> \textsc{modifier letter small reversed glottal stop} at \uni{02E4}
	  \item[] and many more like this
	\end{itemize}
	
	\item[] the rhotic hook <˞> \textsc{modifier letter rhotic hook} at \uni{02DE}
\end{itemize}

Although linguists might expect these characters to belong together with the
character in front of them, at least for <ʰ> \textsc{modifier letter small h} at
\uni{02B0} the Unicode Consortium's decision to treat it as a separate character
is also linguistically correct, because according to the IPA it can be used both
for aspiration (more precisely post-aspiration following the base character) and
pre-aspiration (preceding the base character). Note that there exists a mechanism in
Unicode to force separate characters to be combined (namely by using the
\textsc{zero width joiner} at \uni{200D}), but this seems to be a rather
impractical, and probably not an enforceable solution to us.

\section{Pitfall: No unique diacritic ordering}
\label{pitfall-no-unique-diacritic-ordering}

Also related to diacritics is the question of ordering. To our knowledge, the
International Phonetic Association does not specify a specific ordering for
diacritics that combine with phonetic base symbols; this exercise is left to the
reasoning of the transcriber. However, such marks have to be explicitly ordered
if sequences of them are to be interoperable and compatible. An example is a
labialized aspirated alveolar plosive: <tʷʰ>. There is nothing holding linguists
back from using <tʰʷ> instead (with exactly the same intended meaning). However,
from a technical standpoint, these two sequences are different, e.g.~if both
sequences are used in a document, searching for <tʷʰ> will not find any
instances of <tʰʷ>, and vice versa. Likewise, a creaky voiced syllabic dental
nasal can be encoded in various orders, e.g. <n̪̰̩>, <n̩̰̪> or <n̩̪̰>.

In accordance with the absence of any specification of ordering in the IPA, the
Unicode Standard likewise does not propose any standard orderings. Both leave it
to the user to be consistent. However, there is one aspect of ordering for which
the Unicode Standard does present a canonical solution, which is uncontroversial
from a linguistic perspective. Diacritics in the Unicode Standard
(i.e.~Combining Diacritical Marks, see above) are classified in Canonical
Combining Classes. In practice, the diacritics are distinguished by their
position relative to the base character.\footnote{See
\url{http://unicode.org/reports/tr44/\#Canonical\_Combining\_Class\_Values for a
detailed description}.} When applying a Unicode normalization (NFC or NFD, see
previous section), the diacritics in different positions are put in a specified
order. This process therefore harmonizes the difference between different
encodings, for example, of a midtone creaky voice vowel <ḛ̄>. This grapheme
cluster can be encoded either as <e> + <̄> + <̰> or as <e> + <̰> + <̄> . To
prevent this twofold encoding, the Unicode Standard specifies the second
ordering as canonical (diacritics below before diacritics above).

When encoding a string according to the Unicode Standard, it is possible to do
this either using the NFC (composition) or NFD (decomposition) normalization.
Decomposition implies that precomposed characters (like <á> \textsc{latin small
letter a with acute} at \uni{00E1}) will be split into its parts. This might
sound preferable for a linguistic analysis, as the different diacritics are
separated from the base characters. However, note that most attached elements
like strokes (e.g.~in the <ɨ>), retroflex hooks (e.g.~in <ʐ>) or rhotic hooks
(e.g.~in <ɝ>) will not be decomposed, but strangely enough a cedilla (like in
<ç>) will be decomposed. In general, Unicode decomposition does not behave like
a feature decomposition as expected from a linguistic perspective. It is thus
important to consider Unicode decomposition only as a technical procedure, and
not assume that it is linguistically sensible.

Facing the problem of specifying a consistent ordering of diacritics while
developing a large database of phonological inventories from the world's
languages, \citet[540]{Moran2012} defines a set of diacritic ordering
conventions.\footnote{The most recent version of these conventions is online:
\url{http://phoible.github.io/conventions/}} The conventions are influenced by
the linguistic literature, though some ad-hoc decisions had to be taken. The
goal was to explicitly define all character sequences so that the vast variety
of phonemes found in descriptions of the world's language were normalized into
consistent character sequences, e.g.~if one language description uses and
another , when both are intended to be phonetically equivalent, then a decision
to normalize to one form was taken. For example, when a character sequence
contains more than one character in Spacing Modifier Letters, the order that is
proposed is the following (where <\textbar{}> indicates \textit{or} and <→>
indicates \textit{precedes}):

\begin{itemize}
	\itemsep1pt\parskip0pt\parsep0pt 
	\item \textsc{Spacing Modifier Letters ordering:} ( unreleased <̚> \textbar{} lateral release <ˡ> \textbar{} nasal release <ⁿ>) → ( palatalized <ʲ>) → ( labialized <ʷ>) → ( velarized <ˠ>) → ( pharyngealized <ˤ>) → ( aspirated <ʰ> \textbar{} ejective <ʼ>) → ( long <ː> \textbar{} half-long <ˑ>) 
\end{itemize}

If a character sequence contains more than one diacritic below the base
character, then the place feature is applied first (dental, laminal, apical,
fronted, backed, lowered, raised), then the laryngeal setting (voiced,
voiceless, creaky voice, breathy voice) and finally the syllabic or non-syllabic
marker (for vowels, ATR gets put on between the place and laryngeal setting).
So:

\begin{itemize}
	\itemsep1pt\parskip0pt\parsep0pt 
	\item \textsc{Combining Diacritical Marks (below) ordering:} ( dental <t̪> \textbar{} laminal <t̻> \textbar{} apical <t̺>) → ( fronted <u̟> \textbar{} backed <e̠>) →( lowered <e̞> \textbar{} raised <e̝>) → ( ATR <e̘ e̙>) → ( voiced <s̬> \textbar{} voiceless <n̥> \textbar{} creaky voice <b̰> \textbar{} breathy voice <b̤>) → ( syllabic <n̩> \textbar{} non-syllabic <e̯>) 
\end{itemize}

Character sequences with diacritics above the base character were not
problematic in \citet{Moran2012} because they include only the centralized,
mid-centralized and nasalized combining characters. \citet{Moran2012} marks
tones as singletons with Space Modifier Letters, e.g. \textless{}˦\textgreater{}
for a phonemic high tone, instead of accent diacritics, alleviating potential
conflicts. Building on the work of \citet{Moran2012}, if a character sequence
contains more than one diacritic above the base character, we propose:

\begin{itemize}
	\itemsep1pt\parskip0pt\parsep0pt 
	\item \textsc{Combining Diacritical Marks (above) ordering:} (centralized <ë> \textbar{} mid-centralized <e̽>) → (extra short <ĕ>) →( tone accents, e.g. <è> ) → ( Spacing Modifier Letters ) → ( tone letters, e.g. <e˦>) 
\end{itemize}