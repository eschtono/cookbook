\chapter{IPA meets Unicode}
\label{ipa-meets-unicode}

\section{Introducing the International Phonetic Alphabet (IPA)}
\label{introducing-the-international-phonetic-alphabet-ipa}

The International Phonetic Alphabet (IPA) is a common standard in linguistics to transcribe sounds of spoken language into some Latin-based characters (International Phonetic Association 1999). Although IPA is reasonably easily adhered to with pen and paper, it is not trivial to encode IPA characters electronically. Early work addressing the need for a universal computing environment for writing systems and their computational complexity is discussed in Simons 1989. For a long time, linguists (like all other computer users) were limited to ASCII-encoded 7-bit characters, which only includes Latin characters, numbers and some punctuation and symbols. Restricted to these standard character sets that lacked IPA support or other language-specific graphemes that they needed, linguists devised their own solutions (cf.~Bird and Simons 2003). For example, some chose to represent unavailable graphemes with substitutes, e.g.~the combination of to represent . Tech-savvy linguists redefined selected characters from a character encoding by mapping custom made fonts to those code points. However, one linguist's electronic text would not render properly on another linguist's computer without access to the same font. Further, if two character encodings defined two character sets differently, then data could not be reliably and correctly displayed. This is a common example of the non-interoperability of data and data formats.

To alleviate this problem, during the late 1980s, SAMPA (Speech Assessment Methods Phonetic Alphabet) was created to represent IPA symbols with 7-bit printable ASCII character sequences, e.g. for [ɸ]. Two problems with SAMPA are that (i) it is only a partial encoding of the IPA and (ii) it encodes different languages in separate data tables, instead of a universal alphabet, like IPA. SAMPA tables are derived from phonemes appearing in several European languages that were developed as part of a European Commission-funded project to address technical problems like electronic mail exchange (what is now simply called email). SAMPA is essentially a hack to work around displaying IPA characters, but it provided speech technology and other fields a basis that has been widely adopted and used in code. So, SAMPA was a collection of tables to be compared, instead of a large universal table representing all languages. An extended version of SAMPA, called X-SAMPA, set out to include every symbol in the IPA chart including all diacritics (Wells nd.). X-SAMPA was considered more universally applicable because it consisted of one table that encoded the set of characters that represented phones/segments in IPA across languages. SAMPA and X-SAMPA have been widely used for speech technology and as an encoding system in computational linguistics. Eventually, ASCII-encoding of the IPA became depreciated through the advent of the Unicode Standard. Note however that many popular software packages used for linguistic analyses still require ASCII input, e.g.~RuG/L04\footnote{http://www.let.rug.nl/kleiweg/L04/} and SplitsTree4.\footnote{http://www.splitstree.org/}

Still, there are a few pitfalls to be aware of when using the Unicode Standard to encode IPA. As we have said before, from a linguistic perspective it might look like the Unicode Consortium is making incomprehensible decisions, but it is important to realize that the consortium has tried and is continuing to try to be as consistent as possible across a wide range of use cases, and it does place linguistic traditions above other orthographic possibilities. In general, we strongly suggest linguists not to complain about any decisions in the Unicode Standard, but to try and understand the rationale of the Unicode Consortium (which in our experience is almost always well-conceived) and devise ways to work with any unexpected behaviour. Many of the current problems derive from the fact that the IPA is clearly historically based on the Latin script, but different enough from most other Latin-based writing systems to warrant special attention. This ambivalent status of the IPA glyphs (partly Latin, partly special) is unfortunately also attested in the treatment of IPA in the Unicode Standard. In retrospect, it might have been better to consider the IPA (and other transcription systems) to be a special or new kind of script within the Unicode Standard, and treat the obvious similarity to Latin glyphs as a historical relic. All IPA glyphs would then have their own code points, instead of the current situation in which some IPA glyphs have special code points, while others are treated as being identical to the `regular' Latin characters. Yet, the current situation, however unfortunate, is unlikely to change, so as linguists we will have to learn to deal with the specific pitfalls of IPA within the Unicode Standard. In this section, we will describe these pitfalls in some detail.

\section{Pitfall: There is no single complete Unicode code block for IPA}
\label{pitfall-there-is-no-single-complete-unicode-code-block-for-ipa}

The ambivalent nature of IPA glyphs arises because, on the one hand, the IPA uses Latin-based glyphs like , or . From this perspective, the IPA seems to be just another orthographic tradition using Latin characters, all of which do not get a special treatment within the Unicode Standard (just like e.g.~the French, German, or Danish orthographic traditions do not have a special status). On the other hand, the IPA uses many special symbols (like turned , mirrored and/or extended Latin glyphs ) not found in any other Latin-based writing system. For this reason, and already in the first version of the Unicode Standard (Version 1.0 from 1991), a special block with code points, called ``IPA Extensions'' was included. As noted in Section 4, Pitfall 1, the Unicode Standard code space is subdivided into character blocks, which generally encode characters from a single script. However, as is illustrated by the IPA, characters that form a single writing system may be dispersed across several different character blocks. With its diverse collection of symbols from various scripts and diacritics, the IPA is spread across over 13 blocks in the Unicode Standard:\footnote{This number of blocks depends on whether only IPA-sanctioned symbols are counted or if the phonetic symbols commonly found in the literature are also included, see Moran 2012, Appendix C.}
\begin{itemize}
	\item Basic Latin (30 characters), e.g. <a, b, c, d, e> 
	\item Latin-1 Supplement (4 characters): <æ, ç, ð, ø\textgreater{} 
	\item Latin Extended-A (3 characters): <ħ, ŋ, œ> 
	\item Latin Extended-B (5 characters): <ǀ, ǁ, ǂ, ǃ, ȵ> 
	\item IPA Extensions (70 characters), e.g.: <ɐ, ɑ, ɔ> 
	\item Spacing Modifier Letters (20 characters), e.g.: <ʰ ʷ ˥> 
	\item Combining Diacritical Marks (33 characters), e.g.: <̝ ̥ ̪> 
	\item Greek and Coptic (3 characters): <β, θ, χ> 
	\item Phonetic Extensions (2 characters): <ᴅ, ᴴ> 
	\item Phonetic Extensions Supplement (3 characters): <ᶑ , ᶾ, ᶣ> 
	\item Superscripts and Subscripts (1 character): <ⁿ> 
	\item Arrows (2 characters): \textless{}↑, ↓\textgreater{} 
	\item Latin Extended-C (1 character): <ⱱ> 
\end{itemize}

\section{Pitfall: There are many IPA homoglyphs in Unicode}
\label{pitfall-there-are-many-ipa-homoglyphs-in-unicode}

Another problem is the large number of homoglyphs, i.e.~different characters that have highly similar glyphs (or even completely identical, depending on the font rendering). For example, a speaker of Russian should ideally not use the CYRILLIC SMALL LETTER A at code point U+0430 for IPA transcriptions, but instead the LATIN SMALL LETTER A at code point U+0061, although visually they are mostly indistinguishable, and the Cyrillic character is more easily typed on a Cyrillic keyboard. Another example we commonly encounter is the use of LATIN SMALL LETTER G at U+0067, instead of the sanctioned Unicode Standard IPA character for the voiced velar stop LATIN SMALL LETTER SCRIPT G at U+0261. One begins to question whether this issue is at all apparent to the working linguist, or if they simply use the U+0067 because it is easily keyboarded and thus saves time, whereas the latter must be cumbersomely inserted as a special symbol in most software.\footnote{This issue was recently addressed by the International Phonetic Association, which has taken the stance that both the keyboard LATIN SMALL LETTER G and the LATIN SMALL LETTER SCRIPT G are valid input characters for the voiced velar plosive. Unfortunately, this decision further introduces ambiguity for linguists trying to adhere to a strict Unicode Standard IPA encoding.}

Furthermore, on the one hand even linguists are unlikely to distinguish between the LATIN SMALL LETTER SCHWA at code point U+0259 and LATIN SMALL LETTER TURNED E at U+01DD. On the other hand, non-linguists are unlikely to distinguish any semantic difference between an open back unrounded vowel , the LATIN SMALL LETTER ALPHA at U+0251, and the open front unrounded vowel , LATIN SMALL LETTER A at U+0061. But even among linguists this distinction leads to problems. For example, as pointed out by Mielke (2009), there is a problem stemming from the fact that about 75\% of languages are reported to have a five-vowel system (Maddieson 1984). Historically, linguistic descriptions tend not to include precise audio recording and measurements of formants, so this may lead one to ask if the many characters that are used in phonological description reflects a ``transcriptional bias''. The common use of in transcriptions could be in part due to the ease of typing the letter on an English keyboard (or for older descriptions, the typewriter). We found it to be exceedingly rare that a linguist uses for a low back unrounded vowel.\footnote{One example is Vidal 2001a:75, in which the author states: ``The definition of Pilagá /a/ as {[}+back{]} results from its behavior in certain phonological contexts. For instance, uvular and pharyngeal consonants only occur around /a/ and /o/. Hence, the characterization of /a/ and /o/ as a natural class of (i.e., {[}+back{]} vowels), as opposed to /i/ and /e/.''} They simply use $<$a$>$ as long as there is no opposition to $<$ɑ$>$.\footnote{See Thomason's Language Log post, ``Why I don't love the International Phonetic Alphabet'', at: http://itre.cis.upenn.edu/\textasciitilde{}myl/languagelog/archives/005287.html.} Making things even more problematic, there is an old typographic tradition that the double-story uses a single-story in italics. This leads to the unfortunate effect that in most well-designed fonts the italics of and use the same glyph. If this distinction has to be kept upright in italics, the only solution we can currently offer is to use `slanted' glyphs (i.e.~artificially italicised glyphs) instead of real italics (i.e.~special italics glyphs designed by a typographer).\footnote{For example, the widely used IPA font Doulos SIL (http://scripts.sil.org/cms/scripts/page.php?item\_id=DoulosSIL) does not have real italics. This leads some word-processing software, like Microsoft Word, to produce slanted glyphs instead. That particular combination of font and software application will thus lead to the desired effect. However, note that when the text is transferred to another font (i.e.~one that includes real italics) and/or to another software application (like Apple Pages, which does not perform slanting), then this visual appearance will be lost. In this case we are thus still in the pre-Unicode situation in which the choice of font and rendering software actually matters. The ideal solution from a linguistic point of view would be the introduction of a new IPA code point for a different kind of which explicitly specifies that it should still be rendered as a double-story character when italicized. After informal discussion with various Unicode players, our impression is that this highly restricted problem is not sufficiently urgent to introduce even more -like characters in Unicode (which already lead to much confusion, see Section 4, Pitfall 4). This is a clear situation in which the Unicode Consortium is not just thinking about linguists, but has a more wide-ranging practical view to consider.}

Some other homoglyphs related to encoding IPA in the Unicode Standard are:
\begin{itemize}
	\item The uses of the apostrophe has led to long discussions on the Unicode Standard email list. An English keyboard inputs \textless{}`\textgreater{} APOSTROPHE at U+0027, although the `preferred' Unicode apostrophe is the \textless{}'\textgreater{} RIGHT SINGLE QUOTATION MARK at U+2019. Yet the glottal stop/glottalization/ejective marker is another completely different character, the MODIFIER LETTER APOSTROPHE at U+02BC, but unfortunately looks mostly highly similar to U+2019. 
	\item There is ambiguous encoding of IPA segments within the Unicode Standard. An example is the U+02C1 MODIFIER LETTER REVERSED GLOTTAL STOP vs the U+02E4 MODIFIER LETTER SMALL REVERSED GLOTTAL STOP . Both are denoted in the Unicode Standard as the `pharyngealized diacritic' and both appear in various resources representing phonetic data online. This is thus an example for which the Unicode Standard does not solve the linguistic standardization problem. 
	\item There is at least one case in which the character name assigned by the Unicode Consortium does not match the IPA's description: in the Unicode Standard at U+01C3 is labeled LATIN LETTER RETROFLEX CLICK, but in IPA is an alveolar or postalveolar click (not retroflex). This naming is probably best seen as a simple error in the Unicode Standard. Note that most linguists simply seem to use or <ou>) while ligatures are single characters (e.g. <ʧ> LATIN SMALL LETTER TESH DIGRAPH at U+02A7). Ligatures arose in the context of printing easier-to-read texts, and are included in the Unicode Standard for reasons of legacy encoding. However, their usage is discouraged by the Unicode core specification. Specifically related to IPA, various phonetic combinations of characters (typically affricates) are available as single code-points in the Unicode Standard, but are designated as ``ligatures'' or ``digraphs'' (confusingly both names appear interchangeably). Such glyphs might be used by software to produce a pleasing display, but they should not be hard-coded into the text itself. In the context of IPA, characters like the following ligatures should thus \emph{not} be used. Instead a combination of two characters is preferred: 
	\item <ʣ> LATIN SMALL LETTER DZ DIGRAPH at U+02A3 (use <d> + <z> instead) 
	\item <ʧ> LATIN SMALL LETTER TESH DIGRAPH at U+02A7 (use <t> + <ʃ> instead) 
	\item <ʩ> LATIN SMALL LETTER FENG DIGRAPH at U+02A9 (use <f> + <ŋ> instead) 
\end{itemize}

However, there are a few Unicode characters that are historically ligatures, but which are today considered as simple characters in the Unicode Standard and thus should be used when writing IPA, namely:
\begin{itemize}
	\item <ɮ> LATIN SMALL LETTER LEZH at U+026E 
	\item <œ> LATIN SMALL LIGATURE OE at U+0153 
	\item <ɶ> LATIN LETTER SMALL CAPITAL OE at U+0276 
	\item <æ> LATIN SMALL LETTER AE at U+00E6 
\end{itemize}

\section{Pitfall: The notion of diacritic differs between IPA and Unicode}
\label{pitfall-the-ipa-notion-of-diacritics-is-not-the-same-as-the-unicode-standards-notion-of-diacritics}

Another pitfall is diacritics. The problem is that the meaning of the term `diacritics' as used by the IPA is not the same as it used in the Unicode Standard. Specifically, diacritics in the IPA-sense are either so-called \textsc{Combining Diacritical Marks} or \textsc{Spacing Modifier Letters} in the Unicode Standard. Crucially, Combining Diacritical Marks are by definition combined with the character before them (to form so-called default grapheme clusters, see Section 3). In contrast, Spacing Modifier Letters are by definition \emph{not} combined into grapheme clusters with the preceding character, but simply treated as separate letters. In the context of the IPA, the following IPA-diacritics are actually Spacing Modifier Letters in the Unicode Standard:
\begin{itemize}
	\item Length marks, namely <ː> MODIFIER LETTER TRIANGULAR COLON at U+02D0 and <ˑ> MODIFIER LETTER HALF TRIANGULAR COLON at U+02D1. 
	\item Tone letters, like <˥> MODIFIER LETTER EXTRA-HIGH TONE BAR at U+02E5, and others like this. 
	\item Superscript letters, like <ʰ> MODIFIER LETTER SMALL H at U+02B0 or <ˤ> MODIFIER LETTER SMALL REVERSED GLOTTAL STOP at U+02E4, and others like this. 
	\item <˞> MODIFIER LETTER RHOTIC HOOK at U+02DE. 
\end{itemize}

Although linguists might expect these characters to belong together with the character in front of them, at least for <ʰ> MODIFIER LETTER SMALL H at U+02B0 the Unicode Consortium's decision to treat it as a separate character is also linguistically correct, because according to the IPA it can be used both for aspiration (more precisely postaspiration following the base character) and preaspiration (preceding the base character). Note that there is a mechanism in Unicode to force separate characters to be combined (namely by using the ZERO WIDTH JOINER at U+200D), but this seems to be a rather impractical, and probably not enforceable solution to us.

\section{Pitfall: There is no unique diacritic ordering in IPA, nor in Unicode}
\label{pitfall-neither-the-ipa-nor-the-unicode-standard-enforce-a-unique-diacritic-ordering}

Also related to diacritics is the question of ordering. To our knowledge, the International Phonetic Association does not specify a specific ordering for diacritics that combine with phonetic base symbols; this exercise is left to the reasoning of the transcriber. However, such marks have to be explicitly ordered if sequences of them are to be interoperable and compatible. An example is a labialized aspirated alveolar plosive: <tʷʰ>. There is nothing holding linguists back from using <tʰʷ> instead (with exactly the same intended meaning). However, from a technical standpoint, these two sequences are different, e.g.~if both sequences are used in a document, searching for <tʷʰ> will not find any instances of <tʰʷ>, and vice versa. Likewise, a creaky voiced syllabic dental nasal can be encoded in various orders, e.g. <n̪̰̩>, <n̩̰̪> or <n̩̪̰>.

In accordance with the absence of any specification of ordering in the IPA, the Unicode Standard likewise does not propose any standard orderings. Both leave it to the user to be consistent. However, there is one aspect of ordering for which the Unicode Standard does present a canonical solution, which is uncontroversial from a linguistic perspective. Diacritics in the Unicode Standard (i.e.~Combining Diacritical Marks, see above) are classified in Canonical Combining Classes. In practice, the diacritics are distinguished by their position relative to the base character.\footnote{See http://unicode.org/reports/tr44/\#Canonical\_Combining\_Class\_Values for a detailed description.} When applying a Unicode normalization (NFC or NFD, see previous section), the diacritics in different positions are put in a specified order. This process therefore harmonizes the difference between different encodings, for example, of a midtone creaky voice vowel <ḛ̄>. This grapheme cluster can be encoded either as <e> + <̄> + <̰> or as <e> + <̰> + <̄> . To prevent this twofold encoding, the Unicode Standard specifies the second ordering as canonical (diacritics below before diacritics above).

When encoding a string according to the Unicode Standard, it is possible to do this either using the NFC (``composition'') or NFD (``decomposition'') normalization. Decomposition implies that precomposed characters (like <á> LATIN SMALL LETTER A WITH ACUTE at U+00E1) will be split into its parts. This might sound preferable for a linguistic analysis, as the different diacritics are separated from the base characters. However, note that most attached elements like strokes (e.g.~in the <ɨ>), retroflex hooks (e.g.~in <ʐ>) or rhotic hooks (e.g.~in <ɝ>) will not be decomposed, but strangely enough a cedilla (like in <ç>) will be decomposed. In general, Unicode decomposition does not behave like a feature decomposition as expected from a linguistic perspective. It is thus important to consider Unicode decomposition only as a technical procedure, and not assume that it is linguistically sensible.

Facing the problem of specifying a consistent ordering of diacritics while developing a large database of phonological inventories from the world's languages, Moran (2012: 540) defines a set of diacritic ordering conventions.\footnote{The most recent version of these conventions is online: http://phoible.github.io/conventions/} The conventions are influenced by the linguistic literature, though some ad-hoc decisions had to be taken. The goal was to explicitly define all character sequences so that the vast variety of phonemes found in descriptions of the world's language were normalized into consistent character sequences, e.g.~if one language description uses and another , when both are intended to be phonetically equivalent, then a decision to normalize to one form was taken. For example, when a character sequence contains more than one character in Spacing Modifier Letters, the order that is proposed is the following (where <\textbar{}> indicates ``or'' and <→> indicates ``precedes''):
\begin{itemize}
	\itemsep1pt\parskip0pt\parsep0pt 
	\item \textsc{Spacing Modifier Letters ordering:} ( unreleased <̚> \textbar{} lateral release <ˡ> \textbar{} nasal release <ⁿ>) → ( palatalized <ʲ>) → ( labialized <ʷ>) → ( velarized <ˠ>) → ( pharyngealized <ˤ>) → ( aspirated <ʰ> \textbar{} ejective <ʼ>) → ( long <ː> \textbar{} half-long <ˑ>) 
\end{itemize}

If a character sequence contains more than one diacritic below the base character, then the place feature is applied first (dental, laminal, apical, fronted, backed, lowered, raised), then the laryngeal setting (voiced, voiceless, creaky voice, breathy voice) and finally the syllabic or non-syllabic marker (for vowels, ATR gets put on between the place and laryngeal setting). So:
\begin{itemize}
	\itemsep1pt\parskip0pt\parsep0pt 
	\item \textsc{Combining Diacritical Marks (below) ordering:} ( dental <t̪> \textbar{} laminal <t̻> \textbar{} apical <t̺>) → ( fronted <u̟> \textbar{} backed <e̠>) →( lowered <e̞> \textbar{} raised <e̝>) → ( ATR <e̘ e̙>) → ( voiced <s̬> \textbar{} voiceless <n̥> \textbar{} creaky voice <b̰> \textbar{} breathy voice <b̤>) → ( syllabic <n̩> \textbar{} non-syllabic <e̯>) 
\end{itemize}

Character sequences with diacritics above the base character were not problematic in Moran 2012 because they include only the centralized, mid-centralized and nasalized combining characters. Moran (2012) marks tones as singletons with Space Modifier Letters, e.g. \textless{}˦\textgreater{} for a phonemic high tone, instead of accent diacritics, alleviating potential conflicts. Building on the work of Moran (2012), if a character sequence contains more than one diacritic above the base character, we propose:
\begin{itemize}
	\itemsep1pt\parskip0pt\parsep0pt 
	\item \textsc{Combining Diacritical Marks (above) ordering:} (centralized <ë> \textbar{} mid-centralized <e̽>) → (extra short <ĕ>) →( tone accents, e.g. <è> ) → ( Spacing Modifier Letters ) → ( tone letters, e.g. <e˦>) 
\end{itemize}