# Unicode Cookbook for Linguists

[Steven Moran](https://scholar.google.com/citations?user=PpTOh08AAAAJ&hl=en) & [Michael Cysouw](http://cysouw.de/home/index.html)

## Getting the cookbook

The Unicode Cookbook for Linguists is published in the [Translation and Multilingual Natural Language Processing](http://langsci-press.org/catalog/book/176) series by [Language Science Press](http://langsci-press.org/).

The cookbook is available in its most up-to-date form in this directory as [unicode-cookbook.pdf](https://github.com/unicode-cookbook/cookbook/blob/master/unicode-cookbook.pdf). 

[![License: CC BY 4.0](https://licensebuttons.net/l/by/4.0/80x15.png)](http://creativecommons.org/licenses/by/4.0/)

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.773250.svg)](https://doi.org/10.5281/zenodo.773250)


## Preface

This text is meant as a practical guide for linguists and programmers who work with data in multilingual computational environments. We introduce the basic concepts needed to understand how writing systems and character encodings function, and how they work together.

The intersection of the Unicode Standard and the International Phonetic Alphabet is often met with frustration by users. Nevertheless, the two standards have provided language researchers with the computational architecture needed to process, publish and analyze data from many different languages. We bring to light common, but not always transparent, pitfalls that researchers face when working with Unicode and IPA.

In our research, we use quantitative methods to compare languages to uncover and clarify their phylogenetic relationships. However, the majority of lexical data available from the world's languages is in author- or document-specific orthographies. Having identified and overcome the pitfalls involved in making writing systems and character encodings syntactically and semantically interoperable (to the extent that they can be), we have created a suite of open-source Python and R software packages to work with languages using profiles that adequately describe their orthographic conventions. Using these tools in combination with orthography profiles allows users to tokenize and transliterate text from diverse sources, so that they can be meaningfully compared and analyzed.

We welcome comments and corrections regarding this book, our source code, and the [supplemental case studies](https://github.com/unicode-cookbook/) that we provide online. Please use the [issue tracker](https://github.com/unicode-cookbook/cookbook/issues/), email us directly, or make suggestions on [PaperHive](https://paperhive.org/).

